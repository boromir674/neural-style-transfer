[tox]
envlist =
    {py311, py310, py39, py38}-{dev, sdist, wheel}-{linux, macos, windows}
    coverage
isolated_build = true
skip_missing_interpreters = false
minversion = 3.14
requires = virtualenv >= 20.0.34


[gh-actions]
python =
    3.8: {py38}{, -path, -sdist, -wheel, -dev}
    3.9: {py39}{, -path, -sdist, -wheel, -dev}
    3.10: {py310}{, -path, -sdist, -wheel, -dev}
    3.11: {py311}{, -path, -sdist, -wheel, -dev}


[gh-actions:env]
PLATFORM =
    ubuntu-latest: linux
    macos-latest: macos
    windows-latest: windows


[testenv]
passenv =
    *
    AA_VGG_19
setenv =
# It will overide variables in passenv in case of collision
    PYTHONHASHSEED = 2577074909
    PYTHONBUFFERED = yes
    PYPY3323BUG = 1
    TEST_RESULTS_DIR = {toxinidir}{/}test-results
    COVERAGE_FILE = {toxworkdir}{/}.coverage.{envname}
    JUNIT_TEST_RESULTS = junit-test-results.xml
    TEST_STATUS_DIR = {envtmpdir}
    PY_PACKAGE = artificial_artwork
    DIST_DIR = dist
    MYPYPATH = {toxinidir}{/}src{/}stubs
    black,lint,isort: LINT_ARGS = "src tests scripts"
    # PYTHONPATH = {toxinidir}{/}tests

# by default add the 'test' Extras in case we do an installation
# children envs need to verride if they don't the 'test' Extras
extras = test
commands =
# --cov-config pyproject.toml
    pytest -ra --cov --cov-report=term-missing \
      --cov-report=html:{envdir}/htmlcov --cov-context=test \
      --cov-report=xml:{toxworkdir}/coverage.{envname}.xml \
      {posargs:-n auto} tests

## CI oriented Envs integrating with GH Actions Tox Plugin ##

# DEV generates -> py311-dev-linux, py311-dev-macos, py311-dev-windows, etc
[testenv:{py311, py310, py39, py38, pypy3}-dev{, -linux, -macos, -windows}]
description = Install in 'edit' mode, Run Test Suite and gather Coverage
usedevelop = true

## LOCAL DEV Oriented Envs ##

# DEV -> Default command does not do Coverage
[testenv:dev]
description = Using `python3` in PATH: Install in 'edit' mode & Test
basepython = {env:TOXPYTHON:python3.8}
usedevelop = true
commands =
    pytest -ra {toxinidir}{/}tests {posargs:-vvs}
; commands = pytest {toxinidir}{/}tests \
;     -ra -vvs {posargs}
    ; {posargs:-n auto}

# DEV -> Default command does Coverage
[testenv:dev-cov]
description = Using `python3` in PATH: Install in 'edit' mode, Test & measure Coverage
basepython = {env:TOXPYTHON:python3.8}
usedevelop = true
commands =
    pytest -ra --cov --cov-report=term-missing \
      --cov-report=html:{envdir}/htmlcov --cov-context=test \
      --cov-report=xml:{toxworkdir}/coverage.{envname}.xml \
      {toxinidir}{/}tests
    ;   {posargs:-n auto}


[testenv:dev-gui]
description = Using `python3` in PATH or overriden by TOXPYTHON env var: Install in 'edit' mode and launch the GUI!
basepython = {env:TOXPYTHON:python3}
usedevelop = true
extras = gui
commands = python {toxinidir}{/}gui-demo2.py


[testenv:run]
basepython = {env:TOXPYTHON:python}
; commands = neural-style-transfer {toxinidir}/tests/data/canoe_water.jpg {toxinidir}/tests/data/blue-red-w400-h300.jpg --iterations 103 --location {env:TEST_RESULTS_DIR}
commands = nst {posargs:--iterations 600 --location nst_output}


[testenv:test38]
basepython = {env:TOXPYTHON:python3.8}
deps = pytest
extras = test
use_develop = false
commands = pytest {posargs} -vv


## AUTOMATIONS
[testenv:gen-dev-reqs]
basepython = {env:TOXPYTHON:python}
deps =
    click
    attrs
    numpy>=1.21.0,<1.22.0
    imageio
    ; later versions of tensorflow require smaller version of numpy
    ; this smaller version of numpy had not yet implemented types (for mypy)
    tensorflow==2.2.0
skip_install = true
commands = pip freeze > {toxinidir}/requirements/dev.txt


## COVERAGE
[testenv:coverage]
description = combine coverage from test environments
passenv =
    DIFF_AGAINST
    TOX_COVERAGE_FILE
setenv =
    COVERAGE_FILE = {env:TOX_COVERAGE_FILE:{toxworkdir}/.coverage}
skip_install = true
deps =
    coverage[toml]>=5.1
    diff_cover>=6
parallel_show_output = true
commands_pre = python -c 'import os; print("-----\n" + os.environ.get("COVERAGE_FILE"))'
commands =
    coverage combine --keep
    coverage report --skip-covered --show-missing -i
    coverage xml -o {toxworkdir}/coverage.xml -i
    coverage html -d {toxworkdir}/htmlcov -i
depends = {py311, py310, py39, py38, py37, py36}{, -path, -sdist, -wheel, -dev}


[testenv:clean]
description = Clean the working directory from any previously computed code coverage results.
    Removes any data resulted from measuring code coverage. Useful before running the test suite
    with code coverage enabled.
deps = coverage
skip_install = true
commands = coverage erase

[testenv:report]
description = Show the most recently computed code coverage results.
deps = coverage
skip_install = true
commands = {posargs:coverage report}

[testenv:format-report]
description = Generate xml and html formatted files out of previously computed code coverage results.
deps = coverage
skip_install = true
commands =
    coverage xml
    coverage html



## STATIC TYPE CHECKING
[testenv:mypy]
description = Python source code type hints (mypy)
deps =
    attrs
    click
    numpy
    imageio
    scipy
    mypy
skip_install = true
commands =
    ; mypy --follow-imports skip --install-types {posargs:{toxinidir}/src/}
    mypy --install-types {posargs:{toxinidir}/src/} -v


## PYTHON PACKAGING

[testenv:check]
description = Check the code for compliance with best practises of Python packaging ecosystem (PyPI, pip, Distribute, etc).
deps =
    docutils
    readme-renderer
    pygments
    check-manifest
    pyroma
skip_install = true
commands =
    # we do NOT isolate the build, because otherwise the host system needs something like "apt install python3.8-venv"
    check-manifest -v --no-build-isolation
    pyroma -d {toxinidir}


[testenv:build]
description = Create/build the python package/distribution.
    Creates .tar.gz and .whl files in the 'dist' folder, that can be upload to a pypi index server.
basepython = {env:TOXPYTHON:python3}
deps =
    setuptools >= 40.0.0
skip_install = true
commands_pre =
    # Delete the 'dist' directory and its contents if found
    python -c 'import os; import shutil; exec("if os.path.exists(os.path.join(\"{toxinidir}\", \"dist\")):\n    shutil.rmtree(os.path.join(\"{toxinidir}\", \"dist\"))")'
    # Create a setup.py file that simply invokes setuptools.setup without arguments (since all metadata required for building using setuptools should be present in non python files pyproject.toml and/or setup.cfg)
    python -c 'import os; setup_py = os.path.join("{toxinidir}", "setup.py"); string = "from setuptools import setup\nsetup()"; exec("if not os.path.exists(setup_py):\n    with open(setup_py, \"x\") as f:\n        f.write(string)")'
commands =
    python setup.py sdist bdist_wheel
commands_post =
    # Delete the generated setup.py file
    python -c 'import os; setup_py = os.path.join("{toxinidir}", "setup.py"); exec("if os.path.exists(setup_py):\n    os.remove(setup_py)");'


[testenv:deploy]
description = Deploy the python package to be hosted in a PyPi server. Requires the NEURAL_STYLE_TRANSFER_RELEASE_VERSION
    environment variable to contain the string that represents the semantic version (eg 0.5.3 or 1.0.0) under which
    to release the package to pypi. By default, deploys to the test-pypi server.
    If you want to deploy to the "production" pypi, then you have to set the PYPI_SERVER environment
    variable like `export PYPI_SERVER=pypi`. Also runs certain checks on the packaged distribution (.tar.gz and .whl)
passenv =
    TWINE_*
deps =
    keyring==21.3.0
    twine==3.4.0
skip_install = true
commands_pre =
    python -c 'import os; print("{env:PYPI_SERVER:NOT_FOUND}");'
    ; python -c 'import os; n = "TWINE_USERNAME"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    python -c 'import os; n = "TWINE_PASSWORD"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    ; python -c 'import os; n = "TWINE_PASSWORD"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    # check whether the distributionâ€™s long description will render correctly on PyPI
    ; twine check dist/artificial[\-_]artwork-{env:NEURAL_STYLE_TRANSFER_RELEASE_VERSION:PLEASE_INDICATE_THE_SEM_VER_FOR_RELEASE}*
    python -c 'import os; os.environ["TWINE_USERNAME"] = "OVERRIDE_USERNAME";print("USERNAME: " + os.environ.get("TWINE_USERNAME") + " --> PASS !")'
    python -c 'import os; print("USERNAME: " + os.environ.get("TWINE_USERNAME") + " --> PASS !");'
commands =
    python -c 'import os; print("USERNAME: " + os.environ.get("TWINE_USERNAME") + " --> PASS !");'
    ; twine {posargs:upload --non-interactive} --repository {env:PYPI_SERVER:testpypi --skip-existing} dist/artificial[\-_]artwork-{env:NEURAL_STYLE_TRANSFER_RELEASE_VERSION:PLEASE_INDICATE_THE_SEM_VER_FOR_RELEASE}* --verbose
; commands_post =
    ; pip install --index-url https://test.pypi.org/simple/ --no-deps {env:PY_PACKAGE}=={env:NEURAL_STYLE_TRANSFER_RELEASE_VERSION}


## STATIC ANALYSIS OF CODE

[testenv:prospector]
description = Analyse Python code and output information about errors, potential problems, convention violations and complexity.
    Runs the prospector tool which brings together the functionality of other Python analysis tools such as Pyflakes and McCabe complexity.
    We run tools: Pyflakes, Pyroma, McCabe and Dodgy
basepython = {env:TOXPYTHON:python}
deps = prospector[with_pyroma]
skip_install = true
commands_pre =
    # We do not run pylint, since we have a dedicated pylint env for it.
    # Prospector still tries to read .pylintrc, which causes a crash (because .pylintrc was generated with a pylint version higher than the one supported by prospector)
    # So we temporarily "hide" .pylintrc from prospector, by simply renaming the file to ''.pylintrc-bak
    # Python 3
    python -c 'import os; file = lambda x: os.path.join("{toxinidir}", x); pylintrc = file(".pylintrc"); exec("if os.path.exists(pylintrc):\n    os.rename(pylintrc, file(\".pylintrc-bak\"))");'
    # Python>3.8
    ; python -c 'import os; file = lambda x: os.path.join("{toxinidir}", x); exec("if os.path.exists(pylintrc := file(\".pylintrc\")):\n    os.rename(pylintrc, file(\".pylintrc-bak\"))");'
commands =
    prospector {posargs: src}
    ; prospector {posargs: -t pyflakes -t pyroma -t mccabe -t dodgy -s medium --max-line-length 120 -T -A}
commands_post =
    # We "restore" .pylintrc (to be available to the pylint env command)
    # Copy .pylintrc-bak into .pylintrc and then delete .pylintrc-bak
    python -c 'import os; file = lambda x: os.path.join("{toxinidir}", x); pylintrc_bak = file(".pylintrc-bak"); exec("if os.path.exists(pylintrc_bak):\n    os.rename(pylintrc_bak, file(\".pylintrc\"))");'
    ; python -c 'import os; pylintrc_bak = os.path.join("{toxinidir}", ".pylintrc-bak"); pylintrc = os.path.join("{toxinidir}", ".pylintrc"); exec("if os.path.exists(pylintrc_bak):\n    os.rename(pylintrc_bak, pylintrc)");'
    ; python -c 'import os; pylintrc_bak = os.path.join("{toxinidir}", ".pylintrc-bak"); exec("if os.path.exists(pylintrc_bak):\n    os.remove(pylintrc_bak)")'

[testenv:pylint]
description = Run the Pylint tool to analyse the Python code and output information about errors,
    potential problems and convention violations
basepython = {env:TOXPYTHON:python}
deps =
    click
    attrs
    numpy>=1.21.0,<1.22.0
    imageio
    tensorflow==2.2.0
    pylint==2.7.4
skip_install = false
use_develop = true
commands = python -m pylint {posargs:{toxinidir}/src/artificial_artwork}


## GENERATE ARCHITECTURE GRAPHS

[testenv:pydeps]
description = Visualise the dependency graphs (roughly which module imports which), by examining the
    Python code. The dependency graph(s) are rendered in .svg file(s) and saved on the disk. You can
    use the PYDEPS_GRAPHS environment variable to determine the directory location to store the visualisation(s). If
    the variable is not supplied then the default folder 'dependency-graphs', inside the project's root folder, is used.
    If the directory does not exist it gets created. Requires that the 'dot' executable is in your PATH. Installing the
    graphviz library should make the dot executable available in PATH. Installing 'graphviz':
    * For Linux users using Debian-based distributions (ie Ubuntu, Debian, Mint), please run "sudo apt install graphviz"
    * For MacOS users Homebrew, please run "brew install graphviz"
basepython = {env:TOXPYTHON:python3.8}
passenv =
    HOME
    PYDEPS_GRAPHS
deps =
    pydeps==1.9.13
setenv =
    {[testenv]setenv}
    DEPS_DEFAULT_LOCATION = pydeps
usedevelop = true
changedir = {toxinidir}
commands_pre =
    python -c 'import os; p = "{env:PYDEPS_GRAPHS:pydeps}"; exec("if not os.path.exists(p):\n    os.mkdir(p)");'

commands =
    ; python -c 'import os; dir_path = os.path.join("{toxinidir}", "{env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}"); exec("if not os.path.exists(dir_path):\n    os.mkdir(dir_path)");'
    pydeps --version

    # --max-bacon : exclude nodes that are more than n hops away
    # (default=2, 0 -> infinite)

    # --min-cluster-size : the minimum number of nodes a dependency must have before being clustered (default=0)

    # --max-cluster-size : the maximum number of nodes a dependency can have before the cluster is collapsed to a single node (default=0)
    # --keep-target-cluster : draw target module as a cluster

    # Draw only the source code package inner dependencies
    pydeps src/{env:PY_PACKAGE} --only {env:PY_PACKAGE} --noshow -o {env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}/{env:PY_PACKAGE}_inner_deps.svg
    # Draw the source code package inner and external dependencies
    pydeps src/{env:PY_PACKAGE} --cluster --noshow -o {env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}/{env:PY_PACKAGE}_deps.svg

    # Visualize the package inner dependencies and abstract the external (eg with numpy, scipy, etc) ones
    # Draw the source code package inner and minimum external dependencies
    pydeps src/{env:PY_PACKAGE} --max-cluster-size=2 --keep-target-cluster --noshow -o {env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}/{env:PY_PACKAGE}_target_cluster_deps_one_arrow.svg

    # Draw the source code package inner and all external dependencies
    pydeps src/{env:PY_PACKAGE} --keep-target-cluster --noshow -o {env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}/{env:PY_PACKAGE}_target_cluster_deps_all_arrows.svg

    # increasing max-bacon reveales the dependencies of the dependencies..
    ; pydeps src/{env:PY_PACKAGE} --max-bacon=8 --max-cluster-size=2 --keep-target-cluster --noshow -o {env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}/{env:PY_PACKAGE}-n4.svg

    # increasing max-cluster-size reveales more modules inside the external dependencies and their dependencies..
    ; pydeps src/{env:PY_PACKAGE} --max-bacon=8 --max-cluster-size=5 --keep-target-cluster --noshow -o {env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}/{env:PY_PACKAGE}-n5.svg
    python -c 'import os; print("\nGenerated dependency graph(s), as .svg files.\nThe graph(s) reside in the \"" + os.path.join("{toxinidir}", "{env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}") + "\" directory and you can now view them (ie in your browser).\n")'
    ; python -c 'import os; print("\nGenerated dependency graph(s), as .svg files."); print("The graph(s) reside in the \"" + os.path.join("{toxinidir}", "{env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}") + "\" directory and you can now view them (ie in your browser).\n")'


[testenv:uml]
description = Generate UML (class and package) diagrams by inspecting the code. The diagrams are stored in the
    $UML_DIAGRAMS dir. Runs the pyreverse tool to parse the code and generate the files. This is a pretty legacy tool currently integrated in pylint (not available through pip).
setenv =
    {[testenv]setenv}
    # include dirs to pythonpath to solve issue of inspect lib failing with for some relative imports
    PYTHONPATH={toxinidir}/src/{env:PY_PACKAGE}:{toxinidir}/src/{env:PY_PACKAGE}/utils
    UML_DIAGRAMS=uml-diagrams
deps =
    click
    attrs
    numpy>=1.21.0,<1.22.0
    imageio
    tensorflow==2.2.0
    pylint==2.7.4
skip_install = false
use_develop = true
commands_pre =
    python -c 'from glob import glob; import os; dir = os.path.join("{toxinidir}", "{env:UML_DIAGRAMS}"); exec("if not os.path.isdir(dir):\n    os.mkdir(dir)\nelse:\n    _ = [os.remove(x) for x in glob(dir+\"/*\")]")'
commands =
    python -c 'import sys; print(sys.path)'

    # neural_style_transfer.utils
    pyreverse -o {posargs:png} -A -p utils src/{env:PY_PACKAGE}/utils

    # neural_style_transfer.termination_condition
    pyreverse -o {posargs:png} -A -p termination_condition src/{env:PY_PACKAGE}/termination_condition

    # neural_style_transfer
    pyreverse -o {posargs:png} -A -p {env:PY_PACKAGE} src/{env:PY_PACKAGE}

    # MOVE uml diagram files manually into $UML_DIAGRAMS directory (the pyreverse -p flag does not fully work when invoked with tox)
    python -c 'import shutil, glob; uml_diagrams = glob.glob("classes_*.{posargs:png}", recursive=False); print(uml_diagrams); exec("for file in uml_diagrams:\n    shutil.move(file, \"{env:UML_DIAGRAMS}\")")'
    python -c 'import shutil, glob; uml_diagrams = glob.glob("packages_*.{posargs:png}", recursive=False); print(uml_diagrams); exec("for file in uml_diagrams:\n    shutil.move(file, \"{env:UML_DIAGRAMS}\")")'

    # PRINT message
    python -c 'import os; my_dir = os.getcwd(); print("\nGenerated uml diagram(s), as svg/png files."); print("The diagram(s) reside in the \"" + os.path.join(my_dir, "{env:UML_DIAGRAMS}") + "\" directory.\n")'
