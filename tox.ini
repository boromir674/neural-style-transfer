[tox]
envlist =
    ; {py311, py310, py39, py38}-{dev, sdist, wheel}-{linux, macos, windows}
    {py311, py310, py39, py38}-{sdist, wheel}-{linux, macos, windows}
    ; coverage
isolated_build = true
skip_missing_interpreters = false
minversion = 3.14
requires = virtualenv >= 20.0.34


[gh-actions]
python =
    3.8: {py38}{, -path, -sdist, -wheel, -dev}
    3.9: {py39}{, -path, -sdist, -wheel, -dev}
    3.10: {py310}{, -path, -sdist, -wheel, -dev}
    3.11: {py311}{, -path, -sdist, -wheel, -dev}


[gh-actions:env]
PLATFORM =
    ubuntu-latest: linux
    macos-latest: macos
    windows-latest: windows


[testenv]
passenv =
    *
    AA_VGG_19
setenv =
# It will overide variables in passenv in case of collision
    PYTHONHASHSEED = 2577074909
    PYTHONBUFFERED = yes
    PYPY3323BUG = 1
    TEST_RESULTS_DIR = {toxinidir}{/}test-results
    COVERAGE_FILE = {toxworkdir}{/}.coverage.{envname}
    JUNIT_TEST_RESULTS = junit-test-results.xml
    TEST_STATUS_DIR = {envtmpdir}
    PY_PACKAGE = artificial_artwork
    DIST_DIR = dist
    MYPYPATH = {toxinidir}{/}src{/}stubs
    black,lint,isort: LINT_ARGS = "src tests scripts"
    # PYTHONPATH = {toxinidir}{/}tests

# by default add the 'test' Extras in case we do an installation
# children envs need to verride if they don't the 'test' Extras
extras = test
commands =
# --cov-config pyproject.toml
    pytest -ra --cov --cov-report=term-missing \
      --cov-report=html:{envdir}/htmlcov --cov-context=test \
      --cov-report=xml:{toxworkdir}/coverage.{envname}.xml \
      {posargs:-n auto} tests


## CI oriented Envs integrating with GH Actions Tox Plugin ##

# DEV generates -> py311-dev-linux, py311-dev-macos, py311-dev-windows, etc
[testenv:{py311, py310, py39, py38, pypy3}-dev{, -linux, -macos, -windows}]
description = Install in 'edit' mode, Run Test Suite and gather Coverage
usedevelop = true

# SDIST
[testenv:{py311-, py310-, py39-, py38-,}sdist{, -linux, -macos, -windows}]
description = Install as Source Distribution & Test
basepython = {env:TOXPYTHON:python3}
; commands =
; # --cov-config pyproject.toml
;     pytest -ra --cov --cov-report=term-missing \
;       --cov-report=html:{envdir}/htmlcov --cov-context=test \
;       --cov-report=xml:{toxworkdir}/coverage.{envname}.xml \
;       {posargs:-n auto} tests

# WHEEL
[testenv:{py311-, py310-, py39-, py38-,}wheel{, -linux, -macos, -windows}]
description = Build (our Package) Wheel (along with wheels for its python dependencies) inside an `isolated env`, then install both Wheel and its Test Suite (leveraging `pip install wheel_file[test]`) in the `test env`, and finally run all Unit Tests, while gathering Coverage (using `pytest-cov` plugin)
# Extras: https://python-poetry.org/docs/pyproject/#extras
basepython = {env:TOXPYTHON:python3}
setenv =
    {[testenv]setenv}
    # default value is ./.tox/dist/
    WHEELS_DEST = {toxworkdir}{/}{env:DIST_DIR}
skip_install = true
changedir = {toxinidir}
commands =
    pip wheel --wheel-dir {env:WHEELS_DEST} {toxinidir}
    python -c 'from pathlib import Path; p = Path("{env:WHEELS_DEST}"); print( f"\n --- WHEELS in dir \{p\}:" ); print( [i.name for i in p.iterdir()] );'
    pip install --exists-action w --force-reinstall "{toxworkdir}{/}{env:DIST_DIR}{/}{env:PY_PACKAGE}-{env:PKG_VERSION}-py3-none-any.whl[test]"
    {[testenv]commands}

## LOCAL DEV Oriented Envs ##

# DEV -> Default command does not do Coverage
[testenv:dev]
description = Using `python3` in PATH: Install in 'edit' mode & Test
basepython = {env:TOXPYTHON:python3.8}
usedevelop = true
commands =
    pytest -ra {toxinidir}{/}tests {posargs:-vvs}
    ; {posargs:-n auto}

# DEV -> Default command does Coverage
[testenv:dev-cov]
description = Using `python3` in PATH: Install in 'edit' mode, Test & measure Coverage
basepython = {env:TOXPYTHON:python3.8}
usedevelop = true
commands =
    pytest -ra --cov --cov-report=term-missing \
      --cov-report=html:{envdir}/htmlcov --cov-context=test \
      --cov-report=xml:{toxworkdir}/coverage.{envname}.xml \
      {toxinidir}{/}tests \
      {posargs}
    ;   {posargs:-n auto}


#### Dev DEMO GUI (Stable): Live Update of Generated Image ####
[testenv:dev-gui]
description = Install in `edit` mode and run the `stable` version of the GUI.
basepython = {env:TOXPYTHON:python3.8}
usedevelop = true
commands = python {posargs:{toxinidir}{/}gui-demo-live-update-generated-image.py}

#### Dev DEMO GUI (Experimental) ####
[testenv:dev-gui-exp]
description = Install in `edit` mode and run the `experimental` version of the GUI.
basepython = {env:TOXPYTHON:python3.8}
usedevelop = true
extras = gui
commands = python {posargs:{toxinidir}{/}gui-demo2.py}


##### Dev CLI RUN Algorithm  ####
[testenv:run]
basepython = {env:TOXPYTHON:python}
; commands = neural-style-transfer {toxinidir}/tests/data/canoe_water.jpg {toxinidir}/tests/data/blue-red-w400-h300.jpg --iterations 103 --location {env:TEST_RESULTS_DIR}
commands = nst {posargs:--iterations 600 --location nst_output}


### BUILD SDIST and WHEEL with Build module ###
[testenv:build]
description = Build sdist from source code, and then build Package Wheel from sdist. Creates .tar.gz and .whl files in the {env:DIST_DIR} folder, that can be upload to a pypi index server.
basepython = {env:TOXPYTHON:python3}
setenv =
    {[testenv]setenv}
    # default value is ./.tox/dist/
    WHEELS_DEST = {toxinidir}{/}{env:DIST_DIR}
deps = build
skip_install = true
changedir = {toxinidir}
commands_pre =
    python -c 'import os; import shutil; d = "{env:DIST_DIR}"; exec("if os.path.exists(d):\n    shutil.rmtree(d)");'
commands =
    python -m build {posargs:{toxinidir} --outdir {env:DIST_DIR}}
    python -c 'from pathlib import Path; p = Path("{env:WHEELS_DEST}"); print( f"\n --- WHEELS in dir \{p\}:" ); print( [i.name for i in p.iterdir()] );'
    ; pip install --exists-action w --force-reinstall "{env:DIST_DIR}{/}{env:PY_PACKAGE}-{env:PKG_VERSION}-py3-none-any.whl[test]"
    ; {[testenv]commands}


## AUTOMATIONS
[testenv:gen-dev-reqs]
basepython = {env:TOXPYTHON:python}
deps =
    click
    attrs
    numpy>=1.21.0,<1.22.0
    imageio
    ; later versions of tensorflow require smaller version of numpy
    ; this smaller version of numpy had not yet implemented types (for mypy)
    tensorflow==2.2.0
skip_install = true
commands = pip freeze > {toxinidir}/requirements/dev.txt


## COVERAGE
[testenv:coverage]
description = combine coverage from test environments
passenv =
    DIFF_AGAINST
    TOX_COVERAGE_FILE
setenv =
    COVERAGE_FILE = {env:TOX_COVERAGE_FILE:{toxworkdir}/.coverage}
skip_install = true
deps =
    coverage[toml]>=5.1
    diff_cover>=6
parallel_show_output = true
commands_pre = python -c 'import os; print("-----\n" + os.environ.get("COVERAGE_FILE"))'
commands =
    coverage combine --keep
    coverage report --skip-covered --show-missing -i
    coverage xml -o {toxworkdir}/coverage.xml -i
    coverage html -d {toxworkdir}/htmlcov -i
depends = {py311, py310, py39, py38, py37, py36}{, -path, -sdist, -wheel, -dev}


[testenv:clean]
description = Clean the working directory from any previously computed code coverage results.
    Removes any data resulted from measuring code coverage. Useful before running the test suite
    with code coverage enabled.
deps = coverage
skip_install = true
commands = coverage erase

[testenv:report]
description = Show the most recently computed code coverage results.
deps = coverage
skip_install = true
commands = {posargs:coverage report}

[testenv:format-report]
description = Generate xml and html formatted files out of previously computed code coverage results.
deps = coverage
skip_install = true
commands =
    coverage xml
    coverage html



## STATIC TYPE CHECKING
[testenv:type]
description = Python source code type hints (mypy)
basepython = {env:TOXPYTHON:python3}
deps = mypy
skip_install = true
commands =
    ; mypy --follow-imports skip --install-types {posargs:{toxinidir}/src/}
    mypy --install-types {posargs:{toxinidir}/src/} -v


## PYTHON PACKAGING
; [testenv:build]
; description = Create a source and wheel distribution.
;     Creates .tar.gz and .whl files in the {env:DIST_DIR} folder, that can be upload to a pypi index server.
; basepython = {env:TOXPYTHON:python3.8}
; deps = build
; skip_install = true
; changedir = {toxinidir}
; commands_pre =
;     python -c 'import os; import shutil; d = "{env:DIST_DIR}"; exec("if os.path.exists(d):\n    shutil.rmtree(d)");'
; commands = python -m build {toxinidir} --outdir {env:DIST_DIR}

# Static Checks on "Python Build" Artifacts, such as *.tar.gz (sdist), and *.whl (wheel) files.

# Typically, a tar.gz file is produced as artifact of an 'source distributioin' (sdist) build.
# Eg command: python setup.py sdist

[testenv:check]
description = Check the code for compliance with best practises of Python packaging ecosystem (PyPI, pip, Distribute, etc).
basepython = {env:TOXPYTHON:python3.8}
deps =
    poetry-core
    pyroma
    twine
skip_install = true
commands =
    # Wheel Metadata validation with Pyroma
    ## Check metadata for package wheel, given project Dir
    pyroma --directory {toxinidir}
    
    ## Check metadata for package wheel, given built tar.gz File
    pyroma --file {env:DIST_DIR}/{env:PY_PACKAGE}-{env:PKG_VERSION}.tar.gz

    ## Check metadata for package wheel, given PyPI package name
    ; python -m pyroma --pypi {env:PY_PACKAGE}

    # Checks with Twine
    # if Buld env has ran, then both whl and tar.gz files should exist
    # so here we check them both
    python -m twine check {env:DIST_DIR}/{env:PY_PACKAGE}-{env:PKG_VERSION}*

    # TODO Improvement run 'pyroma --pypi' from some script/CI server after uploading to test-pypi
depends = build


## DEPLOY PYPI
[testenv:deploy]
description = Deploy the python package to be hosted in a PyPI server. Requires the PACKAGE_DIST_VERSION
    environment variable to contain the string that represents the semantic version (eg 0.5.3 or 1.0.0) under which
    to release the package to pypi. By default, deploys to the test-pypi server.
    If you want to deploy to the "production" pypi, then you have to set the PYPI_SERVER environment
    variable like `export PYPI_SERVER=pypi`. Also runs certain checks on the packaged distribution (.tar.gz and .whl)
basepython = {env:TOXPYTHON:python3}
passenv =
    *
    # allow twine credentials to pass as env vars
    TWINE_*

    # this is the 'Distro Version' / 'Build Version' of the package
    # practically, this should be inferred from the `version` value fround in pyproject.toml
    # if `version` in pyproject has a `Major.Minor.Patch` formatted value then,
    # PACKAGE_DIST_VERSION value should `Major.Minor.Patch`

    # if `version` in pyproject is formatted as `Major.Minor.Patch-Prerelase` then,
    # PACKAGE_DIST_VERSION value should be `Major.Minor.Patch.Prerelase0`

    # MUST be an EXACT substring of the file names used by `pip`/`python -m build`
    # when creating tar.gz and whl files as Distributions
    PACKAGE_DIST_VERSION

    PYPI_SERVER
deps =
    keyring==21.3.0
    twine==3.4.0
skip_install = true
commands_pre =
    # VERIFY TARGET PYPI SERVER is set correctly to a supported value
    - python -c 'import os; tw_pypi = os.environ.get("PYPI_SERVER", "testpypi"); exec("if tw_pypi not in {\"pypi\", \"testpypi\"}:\n    print(f\"\\n[ERROR]: Requested to set Target PyPI server to \{tw_pypi\}, but supported alias are [pypi, testpypi], which correspond to setting Target PyPI to production pypi.org or staging test.pypi.org, respectively. Please leverage the PYPI_SERVER env var for indicating the Target PyPI server to deploy to. For production PyPI, use PYPI_SERVER=pypi, for test PyPI use PYPI_SERVER=testpypi or do not set the PYPI_SERVER env var at all.\\n\")\n    exit(1)");'

    # PRINT MESSAGE to USER
    - python -c 'import os; tw_pypi = os.environ.get("PYPI_SERVER", "testpypi"); exec("if tw_pypi == \"pypi\":\n    print(f\"\\n[INFO] Will do a PRODUCTION Deployment to PyPI server at pypi.org\\n\")\nelse:\n    print(f\"\\nWill do a STAGING Deployment to test PyPI server at test.pypi.org\\n\")");'

    # VERIFY PACKAGE_DIST_VERSION is set
    - python -c 'import os; exec("if not os.environ.get(\"PACKAGE_DIST_VERSION\"):\n    print(f\"\\n[ERROR]: Requested to deploy to PyPI, but the PACKAGE_DIST_VERSION env var is not set.\\n\")\n    exit(1)");'

    - python -c 'import os; n = "TWINE_USERNAME"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    - python -c 'import os; n = "TWINE_PASSWORD"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'

    # check whether the distributionâ€™s long description will render correctly on PyPI
    ; twine check dist/artificial[\-_]artwork-{env:PACKAGE_DIST_VERSION:PLEASE_INDICATE_THE_SEM_VER_FOR_RELEASE}*
commands =
    # TAR GZ
    ; python -m twine {posargs:upload --non-interactive} --repository {env:PYPI_SERVER:testpypi --skip-existing} {toxinidir}{/}dist/{env:PY_PACKAGE}-{env:PACKAGE_DIST_VERSION:PLEASE_INDICATE_THE_SEM_VER_FOR_RELEASE}.tar.gz --verbose
    
    # TAR GZ and WHEEL
    python -m twine {posargs:upload --non-interactive} --repository {env:PYPI_SERVER:testpypi --skip-existing} {toxinidir}{/}dist/{env:PY_PACKAGE}-{env:PACKAGE_DIST_VERSION:PLEASE_INDICATE_THE_SEM_VER_FOR_RELEASE}* --verbose


## STATIC ANALYSIS OF CODE

# ALL CHECKS:
# `TOXPYTHON=python3.8 tox -e isort,black,prospector,ruff,pylint`

## RUFF ##
[testenv:ruff]
description = Run the ruff static analysis tool
basepython = {env:TOXPYTHON:python3}
deps = ruff
skip_install = true
commands = ruff {posargs:--help}

## ISORT ##
[testenv:isort]
description = "Check code: `tox -e isort`. Fix code: `APPLY_ISORT= tox -e isort`"
basepython = {env:TOXPYTHON:python3}
deps = isort >= 5.0.0
skip_install = true
changedir = {toxinidir}
commands = isort {posargs:{env:APPLY_ISORT:--check}} "{env:LINT_ARGS:.}"

## BLACK ##
[testenv:black]
description = "Check code: `tox -e black`. Fix code: `APPLY_BLACK= tox -e black`"
basepython = {env:TOXPYTHON:python3}
deps = black
skip_install = true
changedir = {toxinidir}
commands =
    black {posargs:{env:APPLY_BLACK:--check}} \
    --skip-string-normalization --config pyproject.toml \
    "{env:LINT_ARGS:.}"

# Check: `tox -e isort,black`
# Fix: `APPLY_ISORT= APPLY_BLACK= tox -e isort,black`

## PROSPECTOR = Pyflakes, Pyroma, McCabe, and Dodgy ##
[testenv:prospector]
description = Analyse Python code and output information about errors, potential problems, convention violations and complexity.
    Runs the prospector tool which brings together the functionality of other Python analysis tools such as Pyflakes and McCabe complexity.
    We run tools: Pyflakes, Pyroma, McCabe and Dodgy, Profile Validator
basepython = {env:TOXPYTHON:python3}
deps = prospector[with_pyroma]
skip_install = true
commands_pre =
    # We do not run pylint, since we have a dedicated pylint env for it.
    # Prospector still tries to read .pylintrc, which causes a crash (because .pylintrc was generated with a pylint version higher than the one supported by prospector)
    # So we temporarily "hide" .pylintrc from prospector, by simply renaming the file to ''.pylintrc-bak
    # Python 3
    python -c 'import os; file = lambda x: os.path.join("{toxinidir}", x); pylintrc = file(".pylintrc"); exec("if os.path.exists(pylintrc):\n    os.rename(pylintrc, file(\".pylintrc-bak\"))");'
    # Python>3.8
    ; python -c 'import os; file = lambda x: os.path.join("{toxinidir}", x); exec("if os.path.exists(pylintrc := file(\".pylintrc\")):\n    os.rename(pylintrc, file(\".pylintrc-bak\"))");'
commands =
    prospector {posargs: src}
    ; prospector {posargs: -t pyflakes -t pyroma -t mccabe -t dodgy -s medium --max-line-length 120 -T -A}
commands_post =
    # We "restore" .pylintrc (to be available to the pylint env command)
    # Copy .pylintrc-bak into .pylintrc and then delete .pylintrc-bak
    python -c 'import os; file = lambda x: os.path.join("{toxinidir}", x); pylintrc_bak = file(".pylintrc-bak"); exec("if os.path.exists(pylintrc_bak):\n    os.rename(pylintrc_bak, file(\".pylintrc\"))");'
    ; python -c 'import os; pylintrc_bak = os.path.join("{toxinidir}", ".pylintrc-bak"); pylintrc = os.path.join("{toxinidir}", ".pylintrc"); exec("if os.path.exists(pylintrc_bak):\n    os.rename(pylintrc_bak, pylintrc)");'
    ; python -c 'import os; pylintrc_bak = os.path.join("{toxinidir}", ".pylintrc-bak"); exec("if os.path.exists(pylintrc_bak):\n    os.remove(pylintrc_bak)")'


# TOXPYTHON=python3.8 tox -e pylint | tee pylint.log && rm -rf .tox/pylint && grep -E "Your code has been rated at" pylint.log

## PYLINT ##
[testenv:pylint]
description = Run the Pylint tool to analyse the Python code and output information about errors,
    potential problems and convention violations
basepython = {env:TOXPYTHON:python3.8}
deps =
    pylint==2.7.4
skip_install = false
use_develop = true
commands = python -m pylint {posargs:{toxinidir}/src/{env:PY_PACKAGE}}


## GENERATE ARCHITECTURE GRAPHS

[testenv:pydeps]
description = Visualise the dependency graphs (roughly which module imports which), by examining the
    Python code. The dependency graph(s) are rendered in .svg file(s) and saved on the disk. You can
    use the PYDEPS_GRAPHS environment variable to determine the directory location to store the visualisation(s). If
    the variable is not supplied then the default folder 'dependency-graphs', inside the project's root folder, is used.
    If the directory does not exist it gets created. Requires that the 'dot' executable is in your PATH. Installing the
    graphviz library should make the dot executable available in PATH. Installing 'graphviz':
    * For Linux users using Debian-based distributions (ie Ubuntu, Debian, Mint), please run "sudo apt install graphviz"
    * For MacOS users Homebrew, please run "brew install graphviz"
basepython = {env:TOXPYTHON:python3.8}
passenv =
    HOME
    PYDEPS_GRAPHS
deps =
    pydeps==1.9.13
setenv =
    {[testenv]setenv}
    DEPS_DEFAULT_LOCATION = pydeps
usedevelop = true
changedir = {toxinidir}
commands_pre =
    python -c 'import os; p = "{env:PYDEPS_GRAPHS:pydeps}"; exec("if not os.path.exists(p):\n    os.mkdir(p)");'

commands =
    ; python -c 'import os; dir_path = os.path.join("{toxinidir}", "{env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}"); exec("if not os.path.exists(dir_path):\n    os.mkdir(dir_path)");'
    pydeps --version

    # --max-bacon : exclude nodes that are more than n hops away
    # (default=2, 0 -> infinite)

    # --min-cluster-size : the minimum number of nodes a dependency must have before being clustered (default=0)

    # --max-cluster-size : the maximum number of nodes a dependency can have before the cluster is collapsed to a single node (default=0)
    # --keep-target-cluster : draw target module as a cluster

    # Draw only the source code package inner dependencies
    pydeps src/{env:PY_PACKAGE} --only {env:PY_PACKAGE} --noshow -o {env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}/{env:PY_PACKAGE}_inner_deps.svg
    # Draw the source code package inner and external dependencies
    pydeps src/{env:PY_PACKAGE} --cluster --noshow -o {env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}/{env:PY_PACKAGE}_deps.svg

    # Visualize the package inner dependencies and abstract the external (eg with numpy, scipy, etc) ones
    # Draw the source code package inner and minimum external dependencies
    pydeps src/{env:PY_PACKAGE} --max-cluster-size=2 --keep-target-cluster --noshow -o {env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}/{env:PY_PACKAGE}_target_cluster_deps_one_arrow.svg

    # Draw the source code package inner and all external dependencies
    pydeps src/{env:PY_PACKAGE} --keep-target-cluster --noshow -o {env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}/{env:PY_PACKAGE}_target_cluster_deps_all_arrows.svg

    # increasing max-bacon reveales the dependencies of the dependencies..
    ; pydeps src/{env:PY_PACKAGE} --max-bacon=8 --max-cluster-size=2 --keep-target-cluster --noshow -o {env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}/{env:PY_PACKAGE}-n4.svg

    # increasing max-cluster-size reveales more modules inside the external dependencies and their dependencies..
    ; pydeps src/{env:PY_PACKAGE} --max-bacon=8 --max-cluster-size=5 --keep-target-cluster --noshow -o {env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}/{env:PY_PACKAGE}-n5.svg
    python -c 'import os; print("\nGenerated dependency graph(s), as .svg files.\nThe graph(s) reside in the \"" + os.path.join("{toxinidir}", "{env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}") + "\" directory and you can now view them (ie in your browser).\n")'
    ; python -c 'import os; print("\nGenerated dependency graph(s), as .svg files."); print("The graph(s) reside in the \"" + os.path.join("{toxinidir}", "{env:PYDEPS_GRAPHS:{env:DEPS_DEFAULT_LOCATION}}") + "\" directory and you can now view them (ie in your browser).\n")'


[testenv:uml]
description = Generate UML (class and package) diagrams by inspecting the code. The diagrams are stored in the
    $UML_DIAGRAMS dir. Runs the pyreverse tool to parse the code and generate the files. This is a pretty legacy tool currently integrated in pylint (not available through pip).
setenv =
    {[testenv]setenv}
    # include dirs to pythonpath to solve issue of inspect lib failing with for some relative imports
    PYTHONPATH={toxinidir}/src/{env:PY_PACKAGE}:{toxinidir}/src/{env:PY_PACKAGE}/utils
    UML_DIAGRAMS=uml-diagrams
deps =
    click
    attrs
    numpy>=1.21.0,<1.22.0
    imageio
    tensorflow==2.2.0
    pylint==2.7.4
skip_install = false
use_develop = true
commands_pre =
    python -c 'from glob import glob; import os; dir = os.path.join("{toxinidir}", "{env:UML_DIAGRAMS}"); exec("if not os.path.isdir(dir):\n    os.mkdir(dir)\nelse:\n    _ = [os.remove(x) for x in glob(dir+\"/*\")]")'
commands =
    python -c 'import sys; print(sys.path)'

    # neural_style_transfer.utils
    pyreverse -o {posargs:png} -A -p utils src/{env:PY_PACKAGE}/utils

    # neural_style_transfer.termination_condition
    pyreverse -o {posargs:png} -A -p termination_condition src/{env:PY_PACKAGE}/termination_condition

    # neural_style_transfer
    pyreverse -o {posargs:png} -A -p {env:PY_PACKAGE} src/{env:PY_PACKAGE}

    # MOVE uml diagram files manually into $UML_DIAGRAMS directory (the pyreverse -p flag does not fully work when invoked with tox)
    python -c 'import shutil, glob; uml_diagrams = glob.glob("classes_*.{posargs:png}", recursive=False); print(uml_diagrams); exec("for file in uml_diagrams:\n    shutil.move(file, \"{env:UML_DIAGRAMS}\")")'
    python -c 'import shutil, glob; uml_diagrams = glob.glob("packages_*.{posargs:png}", recursive=False); print(uml_diagrams); exec("for file in uml_diagrams:\n    shutil.move(file, \"{env:UML_DIAGRAMS}\")")'

    # PRINT message
    python -c 'import os; my_dir = os.getcwd(); print("\nGenerated uml diagram(s), as svg/png files."); print("The diagram(s) reside in the \"" + os.path.join(my_dir, "{env:UML_DIAGRAMS}") + "\" directory.\n")'



### DOCS ###

## BUILD DOCUMENTATION PAGES ##
[testenv:docs]
description = Build the documentation. The documentation is built using mkdocs.
basepython = {env:TOXPYTHON:python3}
setenv =
    {[testenv]setenv}
    SPELLCHECK=1
extras = docs
usedevelop = true
commands = mkdocs {posargs}

## ALT BUILD DOCUMENTATION PAGES ##
# poetry export -o req-docs.txt -E docs && tox -e docs2
[testenv:docs2]
description = Mkdocs
basepython = {env:TOXPYTHON:python3}
setenv =
    {[testenv]setenv}
    SPELLCHECK=1
deps = -r req-docs.txt
usedevelop = true
commands =
    mkdocs {posargs}

[testenv:docs1]
description = Mkdocs
setenv =
    {[testenv]setenv}
    SPELLCHECK=1
deps = poetry
skip_install = true
commands =
    poetry install --no-root -E docs
    mkdocs {posargs}

## SERVE LIVE DOCUMENTATION ##
[testenv:live-html]
description = Start documentation dev-server (with hot-reloading) for browser preview
setenv =
    {[testenv]setenv}
    SPELLCHECK=1
extras = docs
usedevelop = true
commands = mkdocs serve