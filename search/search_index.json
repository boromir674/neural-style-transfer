{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Artificial Artwork Quick-start Run a demo NST, on sample Content and Style Images: mkdir art export NST_HOST_MOUNT=\"$PWD/art\" # Run containerized NST, and exit container upon finish docker-compose up Check out your Generated Image ! Artificial Artwork: art/canoe_water_w300-h225.jpg+blue-red_w300-h225.jpg-100.png xdg-open art/canoe_water_w300-h225.jpg+blue-red_w300-h225.jpg-100.png Usage Run the nst CLI with the --help option to see the available options. docker run boromir674/neural-style-transfer:1.0.2 --help Development Installation from pypi pip install artificial-artwork Only python3.8 wheel is included atm. Installation from source : git clone https://github.com/boromir674/neural-style-transfer.git pip install ./neural-style-transfer The Neural Style Transfer - CLI heavely depends on Tensorflow (tf) and therefore it is crucial that tf is installed correctly in your Python environment.","title":"Quick Start"},{"location":"#artificial-artwork","text":"","title":"Artificial Artwork"},{"location":"#quick-start","text":"Run a demo NST, on sample Content and Style Images: mkdir art export NST_HOST_MOUNT=\"$PWD/art\" # Run containerized NST, and exit container upon finish docker-compose up Check out your Generated Image ! Artificial Artwork: art/canoe_water_w300-h225.jpg+blue-red_w300-h225.jpg-100.png xdg-open art/canoe_water_w300-h225.jpg+blue-red_w300-h225.jpg-100.png","title":"Quick-start"},{"location":"#usage","text":"Run the nst CLI with the --help option to see the available options. docker run boromir674/neural-style-transfer:1.0.2 --help","title":"Usage"},{"location":"#development","text":"","title":"Development"},{"location":"#installation-from-pypi","text":"pip install artificial-artwork Only python3.8 wheel is included atm.","title":"Installation from pypi"},{"location":"#installation-from-source","text":"git clone https://github.com/boromir674/neural-style-transfer.git pip install ./neural-style-transfer The Neural Style Transfer - CLI heavely depends on Tensorflow (tf) and therefore it is crucial that tf is installed correctly in your Python environment.","title":"Installation from source:"},{"location":"build-process_DAG/","text":"Docker Build Process DAG docker build possible execution paths. Flow Chart, of how exection navigates docker stages (see --target of docker build). If you run docker build . the target used by default is the default_with_demo Stage in the Graph. Dockerfile: ./Dockerfile graph TB; python:3.8.12-slim-bullseye --> base base --> source source --> prod base --> prod_install prod -. \"COPY\" .-> prod_install prod_install --> prod_ready prod_ready --> prod_demo prod_ready --> default prod_demo --> default_with_demo","title":"Docker"},{"location":"build-process_DAG/#docker-build-process-dag","text":"docker build possible execution paths. Flow Chart, of how exection navigates docker stages (see --target of docker build). If you run docker build . the target used by default is the default_with_demo Stage in the Graph. Dockerfile: ./Dockerfile graph TB; python:3.8.12-slim-bullseye --> base base --> source source --> prod base --> prod_install prod -. \"COPY\" .-> prod_install prod_install --> prod_ready prod_ready --> prod_demo prod_ready --> default prod_demo --> default_with_demo","title":"Docker Build Process DAG"},{"location":"cli/","text":"CLI Reference This page provides documentation for our command line tools. entry-point Usage: entry-point [OPTIONS] COMMAND [ARGS]... Options: -V, --version Show the version and exit. --help Show this message and exit. demo Usage: entry-point demo [OPTIONS] Options: -it, --iterations INTEGER Number of iterations to run the algorithm. [default: 100] -o, --output DIRECTORY Location to save the generated images. [default: demo-output] --help Show this message and exit. run Usage: entry-point run [OPTIONS] CONTENT_IMAGE STYLE_IMAGE Options: -it, --iterations INTEGER [default: 100] -l, --location TEXT --help Show this message and exit.","title":"CLI"},{"location":"cli/#cli-reference","text":"This page provides documentation for our command line tools.","title":"CLI Reference"},{"location":"cli/#entry-point","text":"Usage: entry-point [OPTIONS] COMMAND [ARGS]... Options: -V, --version Show the version and exit. --help Show this message and exit.","title":"entry-point"},{"location":"cli/#demo","text":"Usage: entry-point demo [OPTIONS] Options: -it, --iterations INTEGER Number of iterations to run the algorithm. [default: 100] -o, --output DIRECTORY Location to save the generated images. [default: demo-output] --help Show this message and exit.","title":"demo"},{"location":"cli/#run","text":"Usage: entry-point run [OPTIONS] CONTENT_IMAGE STYLE_IMAGE Options: -it, --iterations INTEGER [default: 100] -l, --location TEXT --help Show this message and exit.","title":"run"},{"location":"reference/SUMMARY/","text":"artificial_artwork __version__ _demo _main algorithm cli cmd_demo cost_computer disk_interface disk_operations image image image_factory image_operations image_processor nst_image nst_math nst_tf_algorithm pre_trained_models vgg pretrained_model layers_getter model_handler model_handler_interface model_routines production_networks image_model style_layer_selector style_model graph_builder graph_factory styling_observer termination_condition termination_condition termination_condition_interface termination_condition_adapter termination_condition_adapter_factory tf_session_runner utils","title":"SUMMARY"},{"location":"reference/artificial_artwork/","text":"","title":"artificial_artwork"},{"location":"reference/artificial_artwork/__version__/","text":"","title":"__version__"},{"location":"reference/artificial_artwork/_demo/","text":"","title":"_demo"},{"location":"reference/artificial_artwork/_main/","text":"Bridges the Backend code with the CLI's main (aka run) cmd","title":"_main"},{"location":"reference/artificial_artwork/algorithm/","text":"","title":"algorithm"},{"location":"reference/artificial_artwork/cli/","text":"WithStateAttribute Bases: Protocol Protocol for classes that have a state attribute. Source code in src/artificial_artwork/cli.py 13 14 15 16 class WithStateAttribute ( t . Protocol ): \"\"\"Protocol for classes that have a state attribute.\"\"\" state : t . Any version_msg () artificial_artwork CLI version, lib location and Python version. Get message about artificial_artwork version, location and Python version. Source code in src/artificial_artwork/cli.py 28 29 30 31 32 33 34 35 36 37 38 def version_msg (): \"\"\"artificial_artwork CLI version, lib location and Python version. Get message about artificial_artwork version, location and Python version. \"\"\" # extract everything about version: major, minor, patch and build notes python_version = sys . version message = \"Neural Style Transfer CLI %(version)s from {} (Python {} )\" location = os . path . dirname ( this_file_location ) return message . format ( location , python_version )","title":"cli"},{"location":"reference/artificial_artwork/cli/#artificial_artwork.cli.WithStateAttribute","text":"Bases: Protocol Protocol for classes that have a state attribute. Source code in src/artificial_artwork/cli.py 13 14 15 16 class WithStateAttribute ( t . Protocol ): \"\"\"Protocol for classes that have a state attribute.\"\"\" state : t . Any","title":"WithStateAttribute"},{"location":"reference/artificial_artwork/cli/#artificial_artwork.cli.version_msg","text":"artificial_artwork CLI version, lib location and Python version. Get message about artificial_artwork version, location and Python version. Source code in src/artificial_artwork/cli.py 28 29 30 31 32 33 34 35 36 37 38 def version_msg (): \"\"\"artificial_artwork CLI version, lib location and Python version. Get message about artificial_artwork version, location and Python version. \"\"\" # extract everything about version: major, minor, patch and build notes python_version = sys . version message = \"Neural Style Transfer CLI %(version)s from {} (Python {} )\" location = os . path . dirname ( this_file_location ) return message . format ( location , python_version )","title":"version_msg()"},{"location":"reference/artificial_artwork/cmd_demo/","text":"WithStateAttribute Bases: Protocol Protocol for classes that have a state attribute. Source code in src/artificial_artwork/cmd_demo.py 10 11 12 13 class WithStateAttribute ( t . Protocol ): \"\"\"Protocol for classes that have a state attribute.\"\"\" state : t . Any validate_and_normalize_path ( ctx , param , value ) Custom function to validate and normalize a path. Source code in src/artificial_artwork/cmd_demo.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def validate_and_normalize_path ( ctx , param , value ): \"\"\"Custom function to validate and normalize a path.\"\"\" if value is None : return None path = Path ( value ) if path . is_absolute (): abs_path = path else : current_directory = Path . cwd () abs_path = current_directory / path if not abs_path . exists (): abs_path . mkdir () click . echo ( f 'Folder \" { abs_path } \" created' ) else : # get files inside the folder folder_files = [ f for f in abs_path . iterdir () if f . is_file ()] if len ( folder_files ) > 0 : # ask user whether to delete everything, process as it is or exit click . echo ( f 'Folder \" { abs_path } \" already exists and is not empty.' ) click . echo ( \"What do you want to do?\" ) click . echo ( \"1. Delete everything and start from scratch\" ) click . echo ( \"2. Process the existing files\" ) click . echo ( \"3. Exit\" ) choice = click . prompt ( \"Enter your choice\" , type = int ) if choice == 1 : click . echo ( \"Deleting everything...\" ) for file in folder_files : file . unlink () elif choice == 2 : click . echo ( \"Processing existing files...\" ) elif choice == 3 : click . echo ( \"Exiting...\" ) ctx . exit () else : raise click . BadParameter ( f 'Invalid choice \" { choice } \".' ) return abs_path","title":"cmd_demo"},{"location":"reference/artificial_artwork/cmd_demo/#artificial_artwork.cmd_demo.WithStateAttribute","text":"Bases: Protocol Protocol for classes that have a state attribute. Source code in src/artificial_artwork/cmd_demo.py 10 11 12 13 class WithStateAttribute ( t . Protocol ): \"\"\"Protocol for classes that have a state attribute.\"\"\" state : t . Any","title":"WithStateAttribute"},{"location":"reference/artificial_artwork/cmd_demo/#artificial_artwork.cmd_demo.validate_and_normalize_path","text":"Custom function to validate and normalize a path. Source code in src/artificial_artwork/cmd_demo.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def validate_and_normalize_path ( ctx , param , value ): \"\"\"Custom function to validate and normalize a path.\"\"\" if value is None : return None path = Path ( value ) if path . is_absolute (): abs_path = path else : current_directory = Path . cwd () abs_path = current_directory / path if not abs_path . exists (): abs_path . mkdir () click . echo ( f 'Folder \" { abs_path } \" created' ) else : # get files inside the folder folder_files = [ f for f in abs_path . iterdir () if f . is_file ()] if len ( folder_files ) > 0 : # ask user whether to delete everything, process as it is or exit click . echo ( f 'Folder \" { abs_path } \" already exists and is not empty.' ) click . echo ( \"What do you want to do?\" ) click . echo ( \"1. Delete everything and start from scratch\" ) click . echo ( \"2. Process the existing files\" ) click . echo ( \"3. Exit\" ) choice = click . prompt ( \"Enter your choice\" , type = int ) if choice == 1 : click . echo ( \"Deleting everything...\" ) for file in folder_files : file . unlink () elif choice == 2 : click . echo ( \"Processing existing files...\" ) elif choice == 3 : click . echo ( \"Exiting...\" ) ctx . exit () else : raise click . BadParameter ( f 'Invalid choice \" { choice } \".' ) return abs_path","title":"validate_and_normalize_path()"},{"location":"reference/artificial_artwork/cost_computer/","text":"NSTContentCostComputer Source code in src/artificial_artwork/cost_computer.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 class NSTContentCostComputer : @classmethod def compute ( cls , a_C , a_G ): \"\"\" Computes the content cost Assumption 1: a layer l has been chosen from a (Deep) Neural Network trained on images, that should act as a style model. Then: 1. a_C (3D volume) are the hidden layer activations in the chosen layer (l), when the C image is forward propagated (passed through) in the network. 2. a_G (3D volume) are the hidden layer activations in the chosen layer (l), when the G image is forward propagated (passed through) in the network. 3. The above activations are a n_H x n_W x n_C tensor OR Height x Width x Number_of_Channels Pseudo code for latex expression of the mathematical equation: J_content(C, G) = \\\\frac{1}{4 * n_H * n_W * n_C} * \\\\sum_{all entries} (a^(C) - a^(G))^2 OR J_content(C, G) = sum_{for all entries} (a^(C) - a^(G))^2 / (4 * n_H * n_W * n_C) Note that n_H * n_W * n_C is part of the normalization term. Args: a_C (tensor): of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C a_G (tensor): of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G Returns: (tensor): 1D with 1 scalar value computed using the equation above \"\"\" # Dimensions of a_G (we ommit the first one, which equals to 1) n_H , n_W , n_C = a_G . get_shape () . as_list ()[ 1 :] # Future work: Investigate performance when reshaping a_C and a_G before # computing J_content # a_C_unrolled = tf.reshape(a_C, [first_dim, n_H * n_W, n_C]) # a_G_unrolled = tf.reshape(a_G, [first_dim, n_H * n_W, n_C]) J_content = tf . reduce_sum ( tf . square ( a_C - a_G )) / ( 4 * n_H * n_W * n_C ) return J_content compute ( a_C , a_G ) classmethod Computes the content cost Assumption 1: a layer l has been chosen from a (Deep) Neural Network trained on images, that should act as a style model. Then: 1. a_C (3D volume) are the hidden layer activations in the chosen layer (l), when the C image is forward propagated (passed through) in the network. a_G (3D volume) are the hidden layer activations in the chosen layer (l), when the G image is forward propagated (passed through) in the network. The above activations are a n_H x n_W x n_C tensor OR Height x Width x Number_of_Channels Pseudo code for latex expression of the mathematical equation: J_content(C, G) = \\frac{1}{4 * n_H * n_W * n_C} * \\sum_{all entries} (a^(C) - a^(G))^2 OR J_content(C, G) = sum_{for all entries} (a^(C) - a^(G))^2 / (4 * n_H * n_W * n_C) Note that n_H * n_W * n_C is part of the normalization term. Parameters: Name Type Description Default a_C tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C required a_G tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G required Returns: Type Description tensor 1D with 1 scalar value computed using the equation above Source code in src/artificial_artwork/cost_computer.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @classmethod def compute ( cls , a_C , a_G ): \"\"\" Computes the content cost Assumption 1: a layer l has been chosen from a (Deep) Neural Network trained on images, that should act as a style model. Then: 1. a_C (3D volume) are the hidden layer activations in the chosen layer (l), when the C image is forward propagated (passed through) in the network. 2. a_G (3D volume) are the hidden layer activations in the chosen layer (l), when the G image is forward propagated (passed through) in the network. 3. The above activations are a n_H x n_W x n_C tensor OR Height x Width x Number_of_Channels Pseudo code for latex expression of the mathematical equation: J_content(C, G) = \\\\frac{1}{4 * n_H * n_W * n_C} * \\\\sum_{all entries} (a^(C) - a^(G))^2 OR J_content(C, G) = sum_{for all entries} (a^(C) - a^(G))^2 / (4 * n_H * n_W * n_C) Note that n_H * n_W * n_C is part of the normalization term. Args: a_C (tensor): of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C a_G (tensor): of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G Returns: (tensor): 1D with 1 scalar value computed using the equation above \"\"\" # Dimensions of a_G (we ommit the first one, which equals to 1) n_H , n_W , n_C = a_G . get_shape () . as_list ()[ 1 :] # Future work: Investigate performance when reshaping a_C and a_G before # computing J_content # a_C_unrolled = tf.reshape(a_C, [first_dim, n_H * n_W, n_C]) # a_G_unrolled = tf.reshape(a_G, [first_dim, n_H * n_W, n_C]) J_content = tf . reduce_sum ( tf . square ( a_C - a_G )) / ( 4 * n_H * n_W * n_C ) return J_content NSTLayerStyleCostComputer Source code in src/artificial_artwork/cost_computer.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 class NSTLayerStyleCostComputer : compute_gram = gram_matrix @classmethod def compute ( cls , a_S , a_G ): \"\"\" Compute the Style Cost, using the activations of the l style layer. Mathematical equation written in Latex code: J^{[l]}_style (S, G) = \\\\frac{1}{4 * n_c^2 * (n_H * n_W)^2} \\\\sum^{n_C}_{i=1} \\\\sum^{c_C}_{j=1} (G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2 OR Cost(S, G) = \\\\sum^{n_C}_{i=1} \\\\sum^{c_C}_{j=1} (G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2 / ( 4 * n_c^2 * (n_H * n_W)^2 ) Args: a_S (tensor): hidden layer activations of input image S representing style; shape is (1, n_H, n_W, n_C) a_G (tensor): hidden layer activations of input image G representing style; shape is (1, n_H, n_W, n_C) Returns: (tensor): J_style_layer tensor representing a scalar value, style cost defined above by equation (2) \"\"\" # Dimensions of a_G (we ommit the first one, which equals to 1) n_H , n_W , n_C = a_G . get_shape () . as_list ()[ 1 :] # Reshape the images to have them of shape (n_C, n_H*n_W) a_S = tf . transpose ( tf . reshape ( a_S , [ n_H * n_W , n_C ])) a_G = tf . transpose ( tf . reshape ( a_G , [ n_H * n_W , n_C ])) # Computing gram_matrices for both images S and G GS = cls . compute_gram ( a_S ) GG = cls . compute_gram ( a_G ) # Computing the loss J_style_layer = tf . reduce_sum ( tf . square ( GS - GG )) / ( 4 * n_C ** 2 * ( n_H * n_W ) ** 2 ) return J_style_layer compute ( a_S , a_G ) classmethod Compute the Style Cost, using the activations of the l style layer. Mathematical equation written in Latex code: J^{[l]} style (S, G) = \\frac{1}{4 * n_c^2 * (n_H * n_W)^2} \\sum^{n_C} {i=1} \\sum^{c_C} {j=1} (G^{(S)} {(gram)i,j} - G^{(G)}_{(gram)i,j})^2 OR Cost(S, G) = \\sum^{n_C} {i=1} \\sum^{c_C} {j=1} (G^{(S)} {(gram)i,j} - G^{(G)} {(gram)i,j})^2 / ( 4 * n_c^2 * (n_H * n_W)^2 ) Parameters: Name Type Description Default a_S tensor hidden layer activations of input image S representing style; shape is (1, n_H, n_W, n_C) required a_G tensor hidden layer activations of input image G representing style; shape is (1, n_H, n_W, n_C) required Returns: Type Description tensor J_style_layer tensor representing a scalar value, style cost defined above by equation (2) Source code in src/artificial_artwork/cost_computer.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 @classmethod def compute ( cls , a_S , a_G ): \"\"\" Compute the Style Cost, using the activations of the l style layer. Mathematical equation written in Latex code: J^{[l]}_style (S, G) = \\\\frac{1}{4 * n_c^2 * (n_H * n_W)^2} \\\\sum^{n_C}_{i=1} \\\\sum^{c_C}_{j=1} (G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2 OR Cost(S, G) = \\\\sum^{n_C}_{i=1} \\\\sum^{c_C}_{j=1} (G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2 / ( 4 * n_c^2 * (n_H * n_W)^2 ) Args: a_S (tensor): hidden layer activations of input image S representing style; shape is (1, n_H, n_W, n_C) a_G (tensor): hidden layer activations of input image G representing style; shape is (1, n_H, n_W, n_C) Returns: (tensor): J_style_layer tensor representing a scalar value, style cost defined above by equation (2) \"\"\" # Dimensions of a_G (we ommit the first one, which equals to 1) n_H , n_W , n_C = a_G . get_shape () . as_list ()[ 1 :] # Reshape the images to have them of shape (n_C, n_H*n_W) a_S = tf . transpose ( tf . reshape ( a_S , [ n_H * n_W , n_C ])) a_G = tf . transpose ( tf . reshape ( a_G , [ n_H * n_W , n_C ])) # Computing gram_matrices for both images S and G GS = cls . compute_gram ( a_S ) GG = cls . compute_gram ( a_G ) # Computing the loss J_style_layer = tf . reduce_sum ( tf . square ( GS - GG )) / ( 4 * n_C ** 2 * ( n_H * n_W ) ** 2 ) return J_style_layer NSTStyleCostComputer Source code in src/artificial_artwork/cost_computer.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 class NSTStyleCostComputer : style_layer_cost = NSTLayerStyleCostComputer . compute @classmethod def compute ( cls , tf_session , model_layers ): \"\"\" Computes the overall style cost from several chosen layers Args: tf_session (tf.compat.v1.INteractiveSession): the active interactive tf session model_layers () -- our image model (probably pretrained on large dataset) STYLE_LAYERS -- A python list containing: - the names of the layers we would like to extract style from - a coefficient for each of them Returns: (tensor): J_style - tensor representing a scalar value, style cost defined above by equation (2) \"\"\" # initialize the overall style cost J_style = 0 # for layer_name, coeff in STYLE_LAYERS: for _style_layer_id , nst_style_layer in model_layers : # EG network Layers: L1, L2, L3, L4, L5 # Select the output tensor of the currently selected layer # eg reference to the L3 Layer out = nst_style_layer . neurons # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out # ie Pass Image through Graph/Network Layers and get the output from # the L3 Layer a_S = tf_session . run ( out ) # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that # when we run the session, this will be the activations drawn from the appropriate layer, with G as input. a_G = out # Compute style_cost for the current layer J_style_layer = cls . style_layer_cost ( a_S , a_G ) # Add coeff * J_style_layer of this layer to overall style cost J_style += nst_style_layer . coefficient * J_style_layer return J_style compute ( tf_session , model_layers ) classmethod Computes the overall style cost from several chosen layers Parameters: Name Type Description Default tf_session INteractiveSession the active interactive tf session required STYLE_LAYERS -- A python list containing - the names of the layers we would like to extract style from - a coefficient for each of them required Returns: Type Description tensor J_style - tensor representing a scalar value, style cost defined above by equation (2) Source code in src/artificial_artwork/cost_computer.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 @classmethod def compute ( cls , tf_session , model_layers ): \"\"\" Computes the overall style cost from several chosen layers Args: tf_session (tf.compat.v1.INteractiveSession): the active interactive tf session model_layers () -- our image model (probably pretrained on large dataset) STYLE_LAYERS -- A python list containing: - the names of the layers we would like to extract style from - a coefficient for each of them Returns: (tensor): J_style - tensor representing a scalar value, style cost defined above by equation (2) \"\"\" # initialize the overall style cost J_style = 0 # for layer_name, coeff in STYLE_LAYERS: for _style_layer_id , nst_style_layer in model_layers : # EG network Layers: L1, L2, L3, L4, L5 # Select the output tensor of the currently selected layer # eg reference to the L3 Layer out = nst_style_layer . neurons # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out # ie Pass Image through Graph/Network Layers and get the output from # the L3 Layer a_S = tf_session . run ( out ) # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that # when we run the session, this will be the activations drawn from the appropriate layer, with G as input. a_G = out # Compute style_cost for the current layer J_style_layer = cls . style_layer_cost ( a_S , a_G ) # Add coeff * J_style_layer of this layer to overall style cost J_style += nst_style_layer . coefficient * J_style_layer return J_style","title":"cost_computer"},{"location":"reference/artificial_artwork/cost_computer/#artificial_artwork.cost_computer.NSTContentCostComputer","text":"Source code in src/artificial_artwork/cost_computer.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 class NSTContentCostComputer : @classmethod def compute ( cls , a_C , a_G ): \"\"\" Computes the content cost Assumption 1: a layer l has been chosen from a (Deep) Neural Network trained on images, that should act as a style model. Then: 1. a_C (3D volume) are the hidden layer activations in the chosen layer (l), when the C image is forward propagated (passed through) in the network. 2. a_G (3D volume) are the hidden layer activations in the chosen layer (l), when the G image is forward propagated (passed through) in the network. 3. The above activations are a n_H x n_W x n_C tensor OR Height x Width x Number_of_Channels Pseudo code for latex expression of the mathematical equation: J_content(C, G) = \\\\frac{1}{4 * n_H * n_W * n_C} * \\\\sum_{all entries} (a^(C) - a^(G))^2 OR J_content(C, G) = sum_{for all entries} (a^(C) - a^(G))^2 / (4 * n_H * n_W * n_C) Note that n_H * n_W * n_C is part of the normalization term. Args: a_C (tensor): of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C a_G (tensor): of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G Returns: (tensor): 1D with 1 scalar value computed using the equation above \"\"\" # Dimensions of a_G (we ommit the first one, which equals to 1) n_H , n_W , n_C = a_G . get_shape () . as_list ()[ 1 :] # Future work: Investigate performance when reshaping a_C and a_G before # computing J_content # a_C_unrolled = tf.reshape(a_C, [first_dim, n_H * n_W, n_C]) # a_G_unrolled = tf.reshape(a_G, [first_dim, n_H * n_W, n_C]) J_content = tf . reduce_sum ( tf . square ( a_C - a_G )) / ( 4 * n_H * n_W * n_C ) return J_content","title":"NSTContentCostComputer"},{"location":"reference/artificial_artwork/cost_computer/#artificial_artwork.cost_computer.NSTContentCostComputer.compute","text":"Computes the content cost Assumption 1: a layer l has been chosen from a (Deep) Neural Network trained on images, that should act as a style model. Then: 1. a_C (3D volume) are the hidden layer activations in the chosen layer (l), when the C image is forward propagated (passed through) in the network. a_G (3D volume) are the hidden layer activations in the chosen layer (l), when the G image is forward propagated (passed through) in the network. The above activations are a n_H x n_W x n_C tensor OR Height x Width x Number_of_Channels Pseudo code for latex expression of the mathematical equation: J_content(C, G) = \\frac{1}{4 * n_H * n_W * n_C} * \\sum_{all entries} (a^(C) - a^(G))^2 OR J_content(C, G) = sum_{for all entries} (a^(C) - a^(G))^2 / (4 * n_H * n_W * n_C) Note that n_H * n_W * n_C is part of the normalization term. Parameters: Name Type Description Default a_C tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C required a_G tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G required Returns: Type Description tensor 1D with 1 scalar value computed using the equation above Source code in src/artificial_artwork/cost_computer.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @classmethod def compute ( cls , a_C , a_G ): \"\"\" Computes the content cost Assumption 1: a layer l has been chosen from a (Deep) Neural Network trained on images, that should act as a style model. Then: 1. a_C (3D volume) are the hidden layer activations in the chosen layer (l), when the C image is forward propagated (passed through) in the network. 2. a_G (3D volume) are the hidden layer activations in the chosen layer (l), when the G image is forward propagated (passed through) in the network. 3. The above activations are a n_H x n_W x n_C tensor OR Height x Width x Number_of_Channels Pseudo code for latex expression of the mathematical equation: J_content(C, G) = \\\\frac{1}{4 * n_H * n_W * n_C} * \\\\sum_{all entries} (a^(C) - a^(G))^2 OR J_content(C, G) = sum_{for all entries} (a^(C) - a^(G))^2 / (4 * n_H * n_W * n_C) Note that n_H * n_W * n_C is part of the normalization term. Args: a_C (tensor): of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C a_G (tensor): of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G Returns: (tensor): 1D with 1 scalar value computed using the equation above \"\"\" # Dimensions of a_G (we ommit the first one, which equals to 1) n_H , n_W , n_C = a_G . get_shape () . as_list ()[ 1 :] # Future work: Investigate performance when reshaping a_C and a_G before # computing J_content # a_C_unrolled = tf.reshape(a_C, [first_dim, n_H * n_W, n_C]) # a_G_unrolled = tf.reshape(a_G, [first_dim, n_H * n_W, n_C]) J_content = tf . reduce_sum ( tf . square ( a_C - a_G )) / ( 4 * n_H * n_W * n_C ) return J_content","title":"compute()"},{"location":"reference/artificial_artwork/cost_computer/#artificial_artwork.cost_computer.NSTLayerStyleCostComputer","text":"Source code in src/artificial_artwork/cost_computer.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 class NSTLayerStyleCostComputer : compute_gram = gram_matrix @classmethod def compute ( cls , a_S , a_G ): \"\"\" Compute the Style Cost, using the activations of the l style layer. Mathematical equation written in Latex code: J^{[l]}_style (S, G) = \\\\frac{1}{4 * n_c^2 * (n_H * n_W)^2} \\\\sum^{n_C}_{i=1} \\\\sum^{c_C}_{j=1} (G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2 OR Cost(S, G) = \\\\sum^{n_C}_{i=1} \\\\sum^{c_C}_{j=1} (G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2 / ( 4 * n_c^2 * (n_H * n_W)^2 ) Args: a_S (tensor): hidden layer activations of input image S representing style; shape is (1, n_H, n_W, n_C) a_G (tensor): hidden layer activations of input image G representing style; shape is (1, n_H, n_W, n_C) Returns: (tensor): J_style_layer tensor representing a scalar value, style cost defined above by equation (2) \"\"\" # Dimensions of a_G (we ommit the first one, which equals to 1) n_H , n_W , n_C = a_G . get_shape () . as_list ()[ 1 :] # Reshape the images to have them of shape (n_C, n_H*n_W) a_S = tf . transpose ( tf . reshape ( a_S , [ n_H * n_W , n_C ])) a_G = tf . transpose ( tf . reshape ( a_G , [ n_H * n_W , n_C ])) # Computing gram_matrices for both images S and G GS = cls . compute_gram ( a_S ) GG = cls . compute_gram ( a_G ) # Computing the loss J_style_layer = tf . reduce_sum ( tf . square ( GS - GG )) / ( 4 * n_C ** 2 * ( n_H * n_W ) ** 2 ) return J_style_layer","title":"NSTLayerStyleCostComputer"},{"location":"reference/artificial_artwork/cost_computer/#artificial_artwork.cost_computer.NSTLayerStyleCostComputer.compute","text":"Compute the Style Cost, using the activations of the l style layer. Mathematical equation written in Latex code: J^{[l]} style (S, G) = \\frac{1}{4 * n_c^2 * (n_H * n_W)^2} \\sum^{n_C} {i=1} \\sum^{c_C} {j=1} (G^{(S)} {(gram)i,j} - G^{(G)}_{(gram)i,j})^2 OR Cost(S, G) = \\sum^{n_C} {i=1} \\sum^{c_C} {j=1} (G^{(S)} {(gram)i,j} - G^{(G)} {(gram)i,j})^2 / ( 4 * n_c^2 * (n_H * n_W)^2 ) Parameters: Name Type Description Default a_S tensor hidden layer activations of input image S representing style; shape is (1, n_H, n_W, n_C) required a_G tensor hidden layer activations of input image G representing style; shape is (1, n_H, n_W, n_C) required Returns: Type Description tensor J_style_layer tensor representing a scalar value, style cost defined above by equation (2) Source code in src/artificial_artwork/cost_computer.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 @classmethod def compute ( cls , a_S , a_G ): \"\"\" Compute the Style Cost, using the activations of the l style layer. Mathematical equation written in Latex code: J^{[l]}_style (S, G) = \\\\frac{1}{4 * n_c^2 * (n_H * n_W)^2} \\\\sum^{n_C}_{i=1} \\\\sum^{c_C}_{j=1} (G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2 OR Cost(S, G) = \\\\sum^{n_C}_{i=1} \\\\sum^{c_C}_{j=1} (G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2 / ( 4 * n_c^2 * (n_H * n_W)^2 ) Args: a_S (tensor): hidden layer activations of input image S representing style; shape is (1, n_H, n_W, n_C) a_G (tensor): hidden layer activations of input image G representing style; shape is (1, n_H, n_W, n_C) Returns: (tensor): J_style_layer tensor representing a scalar value, style cost defined above by equation (2) \"\"\" # Dimensions of a_G (we ommit the first one, which equals to 1) n_H , n_W , n_C = a_G . get_shape () . as_list ()[ 1 :] # Reshape the images to have them of shape (n_C, n_H*n_W) a_S = tf . transpose ( tf . reshape ( a_S , [ n_H * n_W , n_C ])) a_G = tf . transpose ( tf . reshape ( a_G , [ n_H * n_W , n_C ])) # Computing gram_matrices for both images S and G GS = cls . compute_gram ( a_S ) GG = cls . compute_gram ( a_G ) # Computing the loss J_style_layer = tf . reduce_sum ( tf . square ( GS - GG )) / ( 4 * n_C ** 2 * ( n_H * n_W ) ** 2 ) return J_style_layer","title":"compute()"},{"location":"reference/artificial_artwork/cost_computer/#artificial_artwork.cost_computer.NSTStyleCostComputer","text":"Source code in src/artificial_artwork/cost_computer.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 class NSTStyleCostComputer : style_layer_cost = NSTLayerStyleCostComputer . compute @classmethod def compute ( cls , tf_session , model_layers ): \"\"\" Computes the overall style cost from several chosen layers Args: tf_session (tf.compat.v1.INteractiveSession): the active interactive tf session model_layers () -- our image model (probably pretrained on large dataset) STYLE_LAYERS -- A python list containing: - the names of the layers we would like to extract style from - a coefficient for each of them Returns: (tensor): J_style - tensor representing a scalar value, style cost defined above by equation (2) \"\"\" # initialize the overall style cost J_style = 0 # for layer_name, coeff in STYLE_LAYERS: for _style_layer_id , nst_style_layer in model_layers : # EG network Layers: L1, L2, L3, L4, L5 # Select the output tensor of the currently selected layer # eg reference to the L3 Layer out = nst_style_layer . neurons # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out # ie Pass Image through Graph/Network Layers and get the output from # the L3 Layer a_S = tf_session . run ( out ) # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that # when we run the session, this will be the activations drawn from the appropriate layer, with G as input. a_G = out # Compute style_cost for the current layer J_style_layer = cls . style_layer_cost ( a_S , a_G ) # Add coeff * J_style_layer of this layer to overall style cost J_style += nst_style_layer . coefficient * J_style_layer return J_style","title":"NSTStyleCostComputer"},{"location":"reference/artificial_artwork/cost_computer/#artificial_artwork.cost_computer.NSTStyleCostComputer.compute","text":"Computes the overall style cost from several chosen layers Parameters: Name Type Description Default tf_session INteractiveSession the active interactive tf session required STYLE_LAYERS -- A python list containing - the names of the layers we would like to extract style from - a coefficient for each of them required Returns: Type Description tensor J_style - tensor representing a scalar value, style cost defined above by equation (2) Source code in src/artificial_artwork/cost_computer.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 @classmethod def compute ( cls , tf_session , model_layers ): \"\"\" Computes the overall style cost from several chosen layers Args: tf_session (tf.compat.v1.INteractiveSession): the active interactive tf session model_layers () -- our image model (probably pretrained on large dataset) STYLE_LAYERS -- A python list containing: - the names of the layers we would like to extract style from - a coefficient for each of them Returns: (tensor): J_style - tensor representing a scalar value, style cost defined above by equation (2) \"\"\" # initialize the overall style cost J_style = 0 # for layer_name, coeff in STYLE_LAYERS: for _style_layer_id , nst_style_layer in model_layers : # EG network Layers: L1, L2, L3, L4, L5 # Select the output tensor of the currently selected layer # eg reference to the L3 Layer out = nst_style_layer . neurons # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out # ie Pass Image through Graph/Network Layers and get the output from # the L3 Layer a_S = tf_session . run ( out ) # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that # when we run the session, this will be the activations drawn from the appropriate layer, with G as input. a_G = out # Compute style_cost for the current layer J_style_layer = cls . style_layer_cost ( a_S , a_G ) # Add coeff * J_style_layer of this layer to overall style cost J_style += nst_style_layer . coefficient * J_style_layer return J_style","title":"compute()"},{"location":"reference/artificial_artwork/disk_interface/","text":"","title":"disk_interface"},{"location":"reference/artificial_artwork/disk_operations/","text":"Disk Bases: DiskInterface Save or load images to and from the disk. Source code in src/artificial_artwork/disk_operations.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Disk ( DiskInterface ): \"\"\"Save or load images to and from the disk.\"\"\" @staticmethod def save_image ( image : NDArray , file_path : str , save_format = None ) -> None : \"\"\"Save a numpy ndarray into a file on the disk. Args: image (NDArray): the image to save into a file file_path (str): the path (on the disk) of the file \"\"\" imageio . imsave ( file_path , image , format = save_format ) @staticmethod def load_image ( file_path : str ) -> NDArray : \"\"\"Load an image as numpy ndarray from a file on the disk. Args: file_path (str): the path (on the disk) of the file Returns: NDArray: the image as numpy ndarray \"\"\" return imageio . imread ( file_path ) load_image ( file_path ) staticmethod Load an image as numpy ndarray from a file on the disk. Parameters: Name Type Description Default file_path str the path (on the disk) of the file required Returns: Name Type Description NDArray NDArray the image as numpy ndarray Source code in src/artificial_artwork/disk_operations.py 20 21 22 23 24 25 26 27 28 29 30 @staticmethod def load_image ( file_path : str ) -> NDArray : \"\"\"Load an image as numpy ndarray from a file on the disk. Args: file_path (str): the path (on the disk) of the file Returns: NDArray: the image as numpy ndarray \"\"\" return imageio . imread ( file_path ) save_image ( image , file_path , save_format = None ) staticmethod Save a numpy ndarray into a file on the disk. Parameters: Name Type Description Default image NDArray the image to save into a file required file_path str the path (on the disk) of the file required Source code in src/artificial_artwork/disk_operations.py 10 11 12 13 14 15 16 17 18 @staticmethod def save_image ( image : NDArray , file_path : str , save_format = None ) -> None : \"\"\"Save a numpy ndarray into a file on the disk. Args: image (NDArray): the image to save into a file file_path (str): the path (on the disk) of the file \"\"\" imageio . imsave ( file_path , image , format = save_format )","title":"disk_operations"},{"location":"reference/artificial_artwork/disk_operations/#artificial_artwork.disk_operations.Disk","text":"Bases: DiskInterface Save or load images to and from the disk. Source code in src/artificial_artwork/disk_operations.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Disk ( DiskInterface ): \"\"\"Save or load images to and from the disk.\"\"\" @staticmethod def save_image ( image : NDArray , file_path : str , save_format = None ) -> None : \"\"\"Save a numpy ndarray into a file on the disk. Args: image (NDArray): the image to save into a file file_path (str): the path (on the disk) of the file \"\"\" imageio . imsave ( file_path , image , format = save_format ) @staticmethod def load_image ( file_path : str ) -> NDArray : \"\"\"Load an image as numpy ndarray from a file on the disk. Args: file_path (str): the path (on the disk) of the file Returns: NDArray: the image as numpy ndarray \"\"\" return imageio . imread ( file_path )","title":"Disk"},{"location":"reference/artificial_artwork/disk_operations/#artificial_artwork.disk_operations.Disk.load_image","text":"Load an image as numpy ndarray from a file on the disk. Parameters: Name Type Description Default file_path str the path (on the disk) of the file required Returns: Name Type Description NDArray NDArray the image as numpy ndarray Source code in src/artificial_artwork/disk_operations.py 20 21 22 23 24 25 26 27 28 29 30 @staticmethod def load_image ( file_path : str ) -> NDArray : \"\"\"Load an image as numpy ndarray from a file on the disk. Args: file_path (str): the path (on the disk) of the file Returns: NDArray: the image as numpy ndarray \"\"\" return imageio . imread ( file_path )","title":"load_image()"},{"location":"reference/artificial_artwork/disk_operations/#artificial_artwork.disk_operations.Disk.save_image","text":"Save a numpy ndarray into a file on the disk. Parameters: Name Type Description Default image NDArray the image to save into a file required file_path str the path (on the disk) of the file required Source code in src/artificial_artwork/disk_operations.py 10 11 12 13 14 15 16 17 18 @staticmethod def save_image ( image : NDArray , file_path : str , save_format = None ) -> None : \"\"\"Save a numpy ndarray into a file on the disk. Args: image (NDArray): the image to save into a file file_path (str): the path (on the disk) of the file \"\"\" imageio . imsave ( file_path , image , format = save_format )","title":"save_image()"},{"location":"reference/artificial_artwork/nst_image/","text":"noisy ( image , ratio , seed = None ) Generates a noisy image by adding random noise to the content_image Source code in src/artificial_artwork/image/image_operations.py 120 121 122 123 124 125 126 127 128 129 130 131 132 def noisy ( image : NDArray , ratio : float , seed : int = None , ) -> NDArray : \"\"\"Generates a noisy image by adding random noise to the content_image\"\"\" if ratio < 0 or 1 < ratio : raise InvalidRatioError ( \"Expected a ratio value x such that 0 <= x <= 1\" ) noise_image = np . random . uniform ( - 20 , 20 , image . shape ) . astype ( \"float32\" ) # Set the input_image to be a weighted average of the content_image and a noise_image return noise_image * ratio + image * ( 1 - ratio )","title":"nst_image"},{"location":"reference/artificial_artwork/nst_image/#artificial_artwork.nst_image.noisy","text":"Generates a noisy image by adding random noise to the content_image Source code in src/artificial_artwork/image/image_operations.py 120 121 122 123 124 125 126 127 128 129 130 131 132 def noisy ( image : NDArray , ratio : float , seed : int = None , ) -> NDArray : \"\"\"Generates a noisy image by adding random noise to the content_image\"\"\" if ratio < 0 or 1 < ratio : raise InvalidRatioError ( \"Expected a ratio value x such that 0 <= x <= 1\" ) noise_image = np . random . uniform ( - 20 , 20 , image . shape ) . astype ( \"float32\" ) # Set the input_image to be a weighted average of the content_image and a noise_image return noise_image * ratio + image * ( 1 - ratio )","title":"noisy()"},{"location":"reference/artificial_artwork/nst_math/","text":"gram_matrix ( matrix ) Compute the Gram matrix of input 2D matrix. In Linear Algebra the Gram matrix G of a set of vectors (u_1, u_2, .. , u_n) is the matrix of dot products, whose entries are: G_{ij} = u^T_i * u_j = numpy.dot(u_i, u_j) OR GA = A * A^T Uses tenforflow to compute the Gram matrix of the input 2D matrix. Parameters: Name Type Description Default matrix type matrix of shape (n_C, n_H * n_W) required Returns: Type Description tensor Gram matrix of A, of shape (n_C, n_C) Source code in src/artificial_artwork/nst_math.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def gram_matrix ( matrix : VolumeType ) -> VolumeType : \"\"\"Compute the Gram matrix of input 2D matrix. In Linear Algebra the Gram matrix G of a set of vectors (u_1, u_2, .. , u_n) is the matrix of dot products, whose entries are: G_{ij} = u^T_i * u_j = numpy.dot(u_i, u_j) OR GA = A * A^T Uses tenforflow to compute the Gram matrix of the input 2D matrix. Args: matrix (type): matrix of shape (n_C, n_H * n_W) Returns: (tf.tensor): Gram matrix of A, of shape (n_C, n_C) \"\"\" return tf . matmul ( matrix , tf . transpose ( matrix ))","title":"nst_math"},{"location":"reference/artificial_artwork/nst_math/#artificial_artwork.nst_math.gram_matrix","text":"Compute the Gram matrix of input 2D matrix. In Linear Algebra the Gram matrix G of a set of vectors (u_1, u_2, .. , u_n) is the matrix of dot products, whose entries are: G_{ij} = u^T_i * u_j = numpy.dot(u_i, u_j) OR GA = A * A^T Uses tenforflow to compute the Gram matrix of the input 2D matrix. Parameters: Name Type Description Default matrix type matrix of shape (n_C, n_H * n_W) required Returns: Type Description tensor Gram matrix of A, of shape (n_C, n_C) Source code in src/artificial_artwork/nst_math.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def gram_matrix ( matrix : VolumeType ) -> VolumeType : \"\"\"Compute the Gram matrix of input 2D matrix. In Linear Algebra the Gram matrix G of a set of vectors (u_1, u_2, .. , u_n) is the matrix of dot products, whose entries are: G_{ij} = u^T_i * u_j = numpy.dot(u_i, u_j) OR GA = A * A^T Uses tenforflow to compute the Gram matrix of the input 2D matrix. Args: matrix (type): matrix of shape (n_C, n_H * n_W) Returns: (tf.tensor): Gram matrix of A, of shape (n_C, n_C) \"\"\" return tf . matmul ( matrix , tf . transpose ( matrix ))","title":"gram_matrix()"},{"location":"reference/artificial_artwork/nst_tf_algorithm/","text":"CostBuilder Source code in src/artificial_artwork/nst_tf_algorithm.py 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 @attr . s class CostBuilder : compute_content_cost = attr . ib () compute_style_cost = attr . ib () # Total cost = alpha * J_content + beta * J_style cost = attr . ib ( init = False , default = None ) # Total Cost content_cost = attr . ib ( init = False , default = None ) style_cost = attr . ib ( init = False , default = None ) # beta parameter (unormalized: does not ad to 1 with alpha) # normaly the style weight should sth like 4 factors bigger than the content weight content_cost_weight = attr . ib ( init = False , default = 10 ) style_cost_weight = attr . ib ( init = False , default = 40 ) def build_content_cost ( self , content_image_activations , generated_image_activations ): # Compute the content cost self . content_cost = self . compute_content_cost ( content_image_activations , generated_image_activations ) def build_style_cost ( self , tf_session , style_layers ): # Compute the style cost self . style_cost = self . compute_style_cost ( tf_session , style_layers ) def build_cost ( self , ** kwargs ): # alpha=10, beta=40): \"\"\"Build the function of the Total Cost (loss function). The Total Cost function J(G) (learning error) is the linear combination of the 'content cost' (J_content) and 'style cost' (J_style). After invoking this method the Cost Function is accessible via the 'cost' attribute. Total cost = alpha * J_content + beta * J_style Or mathematically expressed as: J(G) = alpha * J_content(C, G) + beta * J_style(S, G) where G: Generated Image, C: Content Image, S: Style Image and J, J_content, J_style are mathematical functions Args: alpha (float, optional): hyperparameter to weight content cost. Defaults to 10. beta (float, optional): hyperparameter to weight style cost. Defaults to 40. \"\"\" alpha = kwargs . get ( \"alpha\" , self . content_cost ) beta = kwargs . get ( \"beta\" , self . style_cost ) self . content_cost_weight = alpha self . style_cost_weight = beta self . cost = alpha * self . content_cost + beta * self . style_cost build_cost ( ** kwargs ) Build the function of the Total Cost (loss function). The Total Cost function J(G) (learning error) is the linear combination of the 'content cost' (J_content) and 'style cost' (J_style). After invoking this method the Cost Function is accessible via the 'cost' attribute. Total cost = alpha * J_content + beta * J_style Or mathematically expressed as: J(G) = alpha * J_content(C, G) + beta * J_style(S, G) where G: Generated Image, C: Content Image, S: Style Image and J, J_content, J_style are mathematical functions Parameters: Name Type Description Default alpha float hyperparameter to weight content cost. Defaults to 10. required beta float hyperparameter to weight style cost. Defaults to 40. required Source code in src/artificial_artwork/nst_tf_algorithm.py 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 def build_cost ( self , ** kwargs ): # alpha=10, beta=40): \"\"\"Build the function of the Total Cost (loss function). The Total Cost function J(G) (learning error) is the linear combination of the 'content cost' (J_content) and 'style cost' (J_style). After invoking this method the Cost Function is accessible via the 'cost' attribute. Total cost = alpha * J_content + beta * J_style Or mathematically expressed as: J(G) = alpha * J_content(C, G) + beta * J_style(S, G) where G: Generated Image, C: Content Image, S: Style Image and J, J_content, J_style are mathematical functions Args: alpha (float, optional): hyperparameter to weight content cost. Defaults to 10. beta (float, optional): hyperparameter to weight style cost. Defaults to 40. \"\"\" alpha = kwargs . get ( \"alpha\" , self . content_cost ) beta = kwargs . get ( \"beta\" , self . style_cost ) self . content_cost_weight = alpha self . style_cost_weight = beta self . cost = alpha * self . content_cost + beta * self . style_cost NSTAlgorithmRunner Source code in src/artificial_artwork/nst_tf_algorithm.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 @attr . s class NSTAlgorithmRunner : session_runner = attr . ib () apply_noise = attr . ib () # model_design = attr.ib() optimization = attr . ib ( default = attr . Factory ( lambda : Optimization ())) nst_algorithm = attr . ib ( init = False , default = None ) parameters = attr . ib ( init = False , default = None ) nn_builder = attr . ib ( init = False , default = None ) nn_cost_builder = attr . ib ( init = False , default = None ) # broadcast facilities to notify observers/listeners progress_subject = attr . ib ( init = False , default = attr . Factory ( Subject )) persistance_subject = attr . ib ( init = False , default = attr . Factory ( Subject )) # references to most recently Evaluated Cost values Jt = attr . ib ( init = False , default = None ) Jc = attr . ib ( init = False , default = None ) Js = attr . ib ( init = False , default = None ) # NETWORK_OUTPUT = 'conv4_2' @classmethod def default ( cls , apply_noise ): session_runner = TensorflowSessionRunner . with_default_graph_reset () return NSTAlgorithmRunner ( session_runner , apply_noise ) def run ( self , nst_algorithm , model_design : ModelDesignType , ): ## Prepare ## self . nst_algorithm = nst_algorithm c_image = nst_algorithm . parameters . content_image s_image = nst_algorithm . parameters . style_image image_specs = type ( \"ImageSpecs\" , (), { \"height\" : c_image . matrix . shape [ 1 ], \"width\" : c_image . matrix . shape [ 2 ], \"color_channels\" : c_image . matrix . shape [ 3 ], }, )() print ( \" --- Loading CV Image Model ---\" ) style_network = graph_factory . create ( image_specs , # Input tensor is designed to match images dimensions model_design , # ) # One-Time Operation: APPLY NOISE to Content Image, with a ratio from artificial_artwork.image.image_operations import ImageNoiseAdder noise_adder = ImageNoiseAdder ( seed = 1234 ) RATIO_VALUE_OF_ORIGINAL_PROTOTYPE = 0.6 noisy_content_image_matrix = noise_adder ( # image as numpy ndarry (numpy.typing.NDArray) self . nst_algorithm . parameters . content_image . matrix , # ratio in [0, 1], 0 means no noise, 1 means all noise RATIO_VALUE_OF_ORIGINAL_PROTOTYPE , ) print ( \" --- Building Computations ---\" ) self . nn_builder = NeuralNetBuilder ( style_network , self . session_runner . session ) ### Practically, we PASS the Content Image throught Graph # indicate content_image and the output layer of the Neural Network self . nn_builder . build_activations ( c_image . matrix , model_design . network_design . output_layer , ) # We have passed the User Content Image in the Network and we extracted the output Tensor # from the Output Layer (defined in NetworkDesign) # We will be leveraging this a_C tensor to measure Content Cost against # the Generated Image a_G self . nn_cost_builder = CostBuilder ( NSTContentCostComputer . compute , NSTStyleCostComputer . compute , ) # Content Image was passed through the graph, so we can get the activations self . nn_cost_builder . build_content_cost ( self . nn_builder . a_C , # we have the Content Image activations self . nn_builder . a_G , # Generated Image activations ) ### Practically, we PASS the Style Image throught Graph, and in # combination with Style Layers (and coefficients) we have defined, we # build the Computation Function for the Style Cost self . nn_builder . assign_input ( s_image . matrix ) # manually set the neurons attribute for each NSTStyleLayer # using the loaded cv model (which is a dict of layers) # the NSTStyleLayer ids attribute to query the dict for style_layer_id , nst_style_layer in model_design . network_design . style_layers : # for each selected Style Layer, simply copy reference of Layer from # Pretrained network Graph nst_style_layer . neurons = style_network [ style_layer_id ] # TODO obviously encapsulate the above code elsewhere # Build Style Cost Computation Function self . nn_cost_builder . build_style_cost ( self . session_runner . session , model_design . network_design . style_layers , ) # Since the nn_cost_builder has already built the Style and Content Cost # Computation Functions, now it is capable of building the 'Total Cost' # Total Cost can simply be: TC = alpha * Jc + beta * Js self . nn_cost_builder . build_cost ( alpha = 10 , # content cost weight (raw multiplier) beta = 40 , # style cost weight (raw multiplier) ) self . optimization = Optimization () self . optimization . optimize_against ( self . nn_cost_builder . cost ) ## Run Iterative Learning Algorithm ## print ( \" --- Preparing Iterative Learning Algorithm ---\" ) # Take Input Content Image (as 3-color channel 4D tensor with means already subtracted) # and generate a random noise image as a starting for the Generated # Image (a_G) input_image = noisy_content_image_matrix # Initialize global variables (you need to run the session on the initializer) self . session_runner . run ( tf . compat . v1 . global_variables_initializer ()) ## Practically, PASS the Noisy Content Image through Graph # But out cost builder for example might not utilize the Graphs last Tensor output # since our Style Layers most probably are towards the middle layers of the pretrained network model # here basically we perform the first \"iteration\" outside the loop to # initialize the Generated Image (a_G) with the Noisy Content Image # and make the network produce the activations required for all the Cost Computing operations # and performing Weight Optimization (learning) self . session_runner . run ( style_network [ \"input\" ] . assign ( input_image )) self . perform_nst ( style_network ) def perform_nst ( self , style_network ): print ( \" --- Running Iterative Algorithm ---\" ) # Evaluation of Costs Frequency cost_eval_freq = 20 i = 0 self . time_started = time () while not self . nst_algorithm . parameters . termination_condition . satisfied : # We pass the Curernt Gen Image throguh the Graph and get the next iteration of gen Image generated_image = self . iterate ( style_network ) progress = self . _progress ( generated_image , completed_iterations = i + 1 ) # Evaluate Cost scalars every cost_eval_freq iters if i % cost_eval_freq == 0 : self . Jt , self . Jc , self . Js = self . _eval_cost () progress [ \"metrics\" ] . update ( { \"cost\" : self . Jt , \"content-cost\" : self . Jc , \"style-cost\" : self . Js , \"content-cost-weighted\" : self . nn_cost_builder . content_cost_weight * self . Jc , \"style-cost-weighted\" : self . nn_cost_builder . style_cost_weight * self . Js , } ) self . _print_to_std ( progress ) if i % 20 == 0 : self . _notify_persistance ( progress ) self . _print_to_std ( progress ) progress [ \"metrics\" ][ \"duration\" ] = time () - self . time_started # in seconds self . _notify_progress ( progress ) i += 1 try : self . _notify_persistance ( progress ) except NameError as progress_not_evaluated_error : raise NoIterationsDoneError ( \"The algorithm did not iterate. Probably the \" 'f\" {self.nst_algorithm.parameters.termination_condition} \"' ' termination condition is too \"strict.\"' ) from progress_not_evaluated_error print ( \" --- Finished Learning Algorithm :) ---\" ) def iterate ( self , image_model : t . Dict [ str , Layer ]): # Run the session on the train_step to minimize the total cost # This is our typical iterative learning loop / iteration, where the # weights are adjusted to minimize a cost / objective function self . session_runner . run ([ self . optimization . train_step ]) ## Practically, PASS the current version of the Generated Image through # the Graph # Compute the generated image by running the session on the current model['input'] generated_image = self . session_runner . run ( image_model [ \"input\" ]) return generated_image def _print_to_std ( self , progress ): weighted_Jc = self . nn_cost_builder . content_cost_weight * self . Jc weighted_Js = self . nn_cost_builder . style_cost_weight * self . Js iteration_index : int = progress [ \"metrics\" ][ \"iterations\" ] - 1 print ( f \" Iteration: { iteration_index } \\n \" f \" Jc + Js = { self . Js + self . Jc } \\n \" f \" Total Cost : { self . Jt } \\n \" f \" a * Jc + b * Js = { weighted_Jc + weighted_Js } \\n \" f \" Weighted Content Cost : { weighted_Jc } \\n \" f \" Weighted Style Cost : { weighted_Js } \\n \" f \" Content cost : { self . Jc } \\n \" f \" Style cost : { self . Js } \\n \" ) def _progress ( self , generated_image , completed_iterations : int ) -> Dict : return { \"metrics\" : { \"iterations\" : completed_iterations , # number of iterations completed }, \"content_image_path\" : self . nst_algorithm . parameters . content_image . file_path , \"style_image_path\" : self . nst_algorithm . parameters . style_image . file_path , \"output_path\" : self . nst_algorithm . parameters . output_path , \"matrix\" : generated_image , } def _notify_persistance ( self , progress ): self . persistance_subject . state = type ( \"SubjectState\" , (), progress ) self . persistance_subject . notify () def _notify_progress ( self , progress ): # set subject with the appropriate state to broadcast self . progress_subject . state = type ( \"SubjectState\" , (), progress ) # notify all observers/listeners that have 'subscribed' self . progress_subject . notify () def _eval_cost ( self ): \"\"\"Evaluate Total (Style + Constent) Cost\"\"\" # pass cost objects in session to evaluate them Jt , Jc , Js = self . session_runner . run ( [ self . nn_cost_builder . cost , self . nn_cost_builder . content_cost , self . nn_cost_builder . style_cost , ] ) return Jt , Jc , Js def _print_cost ( self , iteration_index ): weighted_Jc = self . nn_cost_builder . content_cost_weight * self . Jc weighted_Js = self . nn_cost_builder . style_cost_weight * self . Js print ( f \" Iteration: { iteration_index } \\n \" f \" Jc + Js = { self . Js + self . Jc } \\n \" f \" Total Cost : { self . Jt } \\n \" f \" a * Jc + b * Js = { weighted_Jc + weighted_Js } \\n \" f \" Weighted Content Cost : { weighted_Jc } \\n \" f \" Weighted Style Cost : { weighted_Js } \\n \" f \" Content cost : { self . Jc } \\n \" f \" Style cost : { self . Js } \\n \" ) NeuralNetBuilder Configure a pretrained image model to facilitate nst algorithm. Source code in src/artificial_artwork/nst_tf_algorithm.py 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 @attr . s class NeuralNetBuilder : \"\"\"Configure a pretrained image model to facilitate nst algorithm.\"\"\" model = attr . ib () session = attr . ib () output_neurons = attr . ib ( init = False , default = None ) a_C = attr . ib ( init = False , default = None ) a_G = attr . ib ( init = False , default = None ) def assign_input ( self , image ): # Assign the content image to be the input of the VGG model. self . session . run ( self . model [ \"input\" ] . assign ( image )) def build_activations ( self , content_image , model_layer_id : str ): self . assign_input ( content_image ) self . _set_output ( model_layer_id ) self . _setup_activations () def _set_output ( self , model_layer_id : str ): # Select the output tensor of a Neural Network layer self . output_neurons = self . model [ model_layer_id ] def _setup_activations ( self ): # Set a_C to be the hidden layer activation from the layer we have selected # Remember we have re-constructed the pretrained model Network by now. # And we have selected in the NetworkDesign a layer that will bee the # 'Output Layer'. Here we say that the Image Model will be modeling the # Content of the G Image as the output of that selected Output Layer. self . a_C = self . session . run ( self . output_neurons ) # Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that # when we run the session, this will be the activations drawn from the appropriate layer, # with G as input. self . a_G = self . output_neurons","title":"nst_tf_algorithm"},{"location":"reference/artificial_artwork/nst_tf_algorithm/#artificial_artwork.nst_tf_algorithm.CostBuilder","text":"Source code in src/artificial_artwork/nst_tf_algorithm.py 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 @attr . s class CostBuilder : compute_content_cost = attr . ib () compute_style_cost = attr . ib () # Total cost = alpha * J_content + beta * J_style cost = attr . ib ( init = False , default = None ) # Total Cost content_cost = attr . ib ( init = False , default = None ) style_cost = attr . ib ( init = False , default = None ) # beta parameter (unormalized: does not ad to 1 with alpha) # normaly the style weight should sth like 4 factors bigger than the content weight content_cost_weight = attr . ib ( init = False , default = 10 ) style_cost_weight = attr . ib ( init = False , default = 40 ) def build_content_cost ( self , content_image_activations , generated_image_activations ): # Compute the content cost self . content_cost = self . compute_content_cost ( content_image_activations , generated_image_activations ) def build_style_cost ( self , tf_session , style_layers ): # Compute the style cost self . style_cost = self . compute_style_cost ( tf_session , style_layers ) def build_cost ( self , ** kwargs ): # alpha=10, beta=40): \"\"\"Build the function of the Total Cost (loss function). The Total Cost function J(G) (learning error) is the linear combination of the 'content cost' (J_content) and 'style cost' (J_style). After invoking this method the Cost Function is accessible via the 'cost' attribute. Total cost = alpha * J_content + beta * J_style Or mathematically expressed as: J(G) = alpha * J_content(C, G) + beta * J_style(S, G) where G: Generated Image, C: Content Image, S: Style Image and J, J_content, J_style are mathematical functions Args: alpha (float, optional): hyperparameter to weight content cost. Defaults to 10. beta (float, optional): hyperparameter to weight style cost. Defaults to 40. \"\"\" alpha = kwargs . get ( \"alpha\" , self . content_cost ) beta = kwargs . get ( \"beta\" , self . style_cost ) self . content_cost_weight = alpha self . style_cost_weight = beta self . cost = alpha * self . content_cost + beta * self . style_cost","title":"CostBuilder"},{"location":"reference/artificial_artwork/nst_tf_algorithm/#artificial_artwork.nst_tf_algorithm.CostBuilder.build_cost","text":"Build the function of the Total Cost (loss function). The Total Cost function J(G) (learning error) is the linear combination of the 'content cost' (J_content) and 'style cost' (J_style). After invoking this method the Cost Function is accessible via the 'cost' attribute. Total cost = alpha * J_content + beta * J_style Or mathematically expressed as: J(G) = alpha * J_content(C, G) + beta * J_style(S, G) where G: Generated Image, C: Content Image, S: Style Image and J, J_content, J_style are mathematical functions Parameters: Name Type Description Default alpha float hyperparameter to weight content cost. Defaults to 10. required beta float hyperparameter to weight style cost. Defaults to 40. required Source code in src/artificial_artwork/nst_tf_algorithm.py 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 def build_cost ( self , ** kwargs ): # alpha=10, beta=40): \"\"\"Build the function of the Total Cost (loss function). The Total Cost function J(G) (learning error) is the linear combination of the 'content cost' (J_content) and 'style cost' (J_style). After invoking this method the Cost Function is accessible via the 'cost' attribute. Total cost = alpha * J_content + beta * J_style Or mathematically expressed as: J(G) = alpha * J_content(C, G) + beta * J_style(S, G) where G: Generated Image, C: Content Image, S: Style Image and J, J_content, J_style are mathematical functions Args: alpha (float, optional): hyperparameter to weight content cost. Defaults to 10. beta (float, optional): hyperparameter to weight style cost. Defaults to 40. \"\"\" alpha = kwargs . get ( \"alpha\" , self . content_cost ) beta = kwargs . get ( \"beta\" , self . style_cost ) self . content_cost_weight = alpha self . style_cost_weight = beta self . cost = alpha * self . content_cost + beta * self . style_cost","title":"build_cost()"},{"location":"reference/artificial_artwork/nst_tf_algorithm/#artificial_artwork.nst_tf_algorithm.NSTAlgorithmRunner","text":"Source code in src/artificial_artwork/nst_tf_algorithm.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 @attr . s class NSTAlgorithmRunner : session_runner = attr . ib () apply_noise = attr . ib () # model_design = attr.ib() optimization = attr . ib ( default = attr . Factory ( lambda : Optimization ())) nst_algorithm = attr . ib ( init = False , default = None ) parameters = attr . ib ( init = False , default = None ) nn_builder = attr . ib ( init = False , default = None ) nn_cost_builder = attr . ib ( init = False , default = None ) # broadcast facilities to notify observers/listeners progress_subject = attr . ib ( init = False , default = attr . Factory ( Subject )) persistance_subject = attr . ib ( init = False , default = attr . Factory ( Subject )) # references to most recently Evaluated Cost values Jt = attr . ib ( init = False , default = None ) Jc = attr . ib ( init = False , default = None ) Js = attr . ib ( init = False , default = None ) # NETWORK_OUTPUT = 'conv4_2' @classmethod def default ( cls , apply_noise ): session_runner = TensorflowSessionRunner . with_default_graph_reset () return NSTAlgorithmRunner ( session_runner , apply_noise ) def run ( self , nst_algorithm , model_design : ModelDesignType , ): ## Prepare ## self . nst_algorithm = nst_algorithm c_image = nst_algorithm . parameters . content_image s_image = nst_algorithm . parameters . style_image image_specs = type ( \"ImageSpecs\" , (), { \"height\" : c_image . matrix . shape [ 1 ], \"width\" : c_image . matrix . shape [ 2 ], \"color_channels\" : c_image . matrix . shape [ 3 ], }, )() print ( \" --- Loading CV Image Model ---\" ) style_network = graph_factory . create ( image_specs , # Input tensor is designed to match images dimensions model_design , # ) # One-Time Operation: APPLY NOISE to Content Image, with a ratio from artificial_artwork.image.image_operations import ImageNoiseAdder noise_adder = ImageNoiseAdder ( seed = 1234 ) RATIO_VALUE_OF_ORIGINAL_PROTOTYPE = 0.6 noisy_content_image_matrix = noise_adder ( # image as numpy ndarry (numpy.typing.NDArray) self . nst_algorithm . parameters . content_image . matrix , # ratio in [0, 1], 0 means no noise, 1 means all noise RATIO_VALUE_OF_ORIGINAL_PROTOTYPE , ) print ( \" --- Building Computations ---\" ) self . nn_builder = NeuralNetBuilder ( style_network , self . session_runner . session ) ### Practically, we PASS the Content Image throught Graph # indicate content_image and the output layer of the Neural Network self . nn_builder . build_activations ( c_image . matrix , model_design . network_design . output_layer , ) # We have passed the User Content Image in the Network and we extracted the output Tensor # from the Output Layer (defined in NetworkDesign) # We will be leveraging this a_C tensor to measure Content Cost against # the Generated Image a_G self . nn_cost_builder = CostBuilder ( NSTContentCostComputer . compute , NSTStyleCostComputer . compute , ) # Content Image was passed through the graph, so we can get the activations self . nn_cost_builder . build_content_cost ( self . nn_builder . a_C , # we have the Content Image activations self . nn_builder . a_G , # Generated Image activations ) ### Practically, we PASS the Style Image throught Graph, and in # combination with Style Layers (and coefficients) we have defined, we # build the Computation Function for the Style Cost self . nn_builder . assign_input ( s_image . matrix ) # manually set the neurons attribute for each NSTStyleLayer # using the loaded cv model (which is a dict of layers) # the NSTStyleLayer ids attribute to query the dict for style_layer_id , nst_style_layer in model_design . network_design . style_layers : # for each selected Style Layer, simply copy reference of Layer from # Pretrained network Graph nst_style_layer . neurons = style_network [ style_layer_id ] # TODO obviously encapsulate the above code elsewhere # Build Style Cost Computation Function self . nn_cost_builder . build_style_cost ( self . session_runner . session , model_design . network_design . style_layers , ) # Since the nn_cost_builder has already built the Style and Content Cost # Computation Functions, now it is capable of building the 'Total Cost' # Total Cost can simply be: TC = alpha * Jc + beta * Js self . nn_cost_builder . build_cost ( alpha = 10 , # content cost weight (raw multiplier) beta = 40 , # style cost weight (raw multiplier) ) self . optimization = Optimization () self . optimization . optimize_against ( self . nn_cost_builder . cost ) ## Run Iterative Learning Algorithm ## print ( \" --- Preparing Iterative Learning Algorithm ---\" ) # Take Input Content Image (as 3-color channel 4D tensor with means already subtracted) # and generate a random noise image as a starting for the Generated # Image (a_G) input_image = noisy_content_image_matrix # Initialize global variables (you need to run the session on the initializer) self . session_runner . run ( tf . compat . v1 . global_variables_initializer ()) ## Practically, PASS the Noisy Content Image through Graph # But out cost builder for example might not utilize the Graphs last Tensor output # since our Style Layers most probably are towards the middle layers of the pretrained network model # here basically we perform the first \"iteration\" outside the loop to # initialize the Generated Image (a_G) with the Noisy Content Image # and make the network produce the activations required for all the Cost Computing operations # and performing Weight Optimization (learning) self . session_runner . run ( style_network [ \"input\" ] . assign ( input_image )) self . perform_nst ( style_network ) def perform_nst ( self , style_network ): print ( \" --- Running Iterative Algorithm ---\" ) # Evaluation of Costs Frequency cost_eval_freq = 20 i = 0 self . time_started = time () while not self . nst_algorithm . parameters . termination_condition . satisfied : # We pass the Curernt Gen Image throguh the Graph and get the next iteration of gen Image generated_image = self . iterate ( style_network ) progress = self . _progress ( generated_image , completed_iterations = i + 1 ) # Evaluate Cost scalars every cost_eval_freq iters if i % cost_eval_freq == 0 : self . Jt , self . Jc , self . Js = self . _eval_cost () progress [ \"metrics\" ] . update ( { \"cost\" : self . Jt , \"content-cost\" : self . Jc , \"style-cost\" : self . Js , \"content-cost-weighted\" : self . nn_cost_builder . content_cost_weight * self . Jc , \"style-cost-weighted\" : self . nn_cost_builder . style_cost_weight * self . Js , } ) self . _print_to_std ( progress ) if i % 20 == 0 : self . _notify_persistance ( progress ) self . _print_to_std ( progress ) progress [ \"metrics\" ][ \"duration\" ] = time () - self . time_started # in seconds self . _notify_progress ( progress ) i += 1 try : self . _notify_persistance ( progress ) except NameError as progress_not_evaluated_error : raise NoIterationsDoneError ( \"The algorithm did not iterate. Probably the \" 'f\" {self.nst_algorithm.parameters.termination_condition} \"' ' termination condition is too \"strict.\"' ) from progress_not_evaluated_error print ( \" --- Finished Learning Algorithm :) ---\" ) def iterate ( self , image_model : t . Dict [ str , Layer ]): # Run the session on the train_step to minimize the total cost # This is our typical iterative learning loop / iteration, where the # weights are adjusted to minimize a cost / objective function self . session_runner . run ([ self . optimization . train_step ]) ## Practically, PASS the current version of the Generated Image through # the Graph # Compute the generated image by running the session on the current model['input'] generated_image = self . session_runner . run ( image_model [ \"input\" ]) return generated_image def _print_to_std ( self , progress ): weighted_Jc = self . nn_cost_builder . content_cost_weight * self . Jc weighted_Js = self . nn_cost_builder . style_cost_weight * self . Js iteration_index : int = progress [ \"metrics\" ][ \"iterations\" ] - 1 print ( f \" Iteration: { iteration_index } \\n \" f \" Jc + Js = { self . Js + self . Jc } \\n \" f \" Total Cost : { self . Jt } \\n \" f \" a * Jc + b * Js = { weighted_Jc + weighted_Js } \\n \" f \" Weighted Content Cost : { weighted_Jc } \\n \" f \" Weighted Style Cost : { weighted_Js } \\n \" f \" Content cost : { self . Jc } \\n \" f \" Style cost : { self . Js } \\n \" ) def _progress ( self , generated_image , completed_iterations : int ) -> Dict : return { \"metrics\" : { \"iterations\" : completed_iterations , # number of iterations completed }, \"content_image_path\" : self . nst_algorithm . parameters . content_image . file_path , \"style_image_path\" : self . nst_algorithm . parameters . style_image . file_path , \"output_path\" : self . nst_algorithm . parameters . output_path , \"matrix\" : generated_image , } def _notify_persistance ( self , progress ): self . persistance_subject . state = type ( \"SubjectState\" , (), progress ) self . persistance_subject . notify () def _notify_progress ( self , progress ): # set subject with the appropriate state to broadcast self . progress_subject . state = type ( \"SubjectState\" , (), progress ) # notify all observers/listeners that have 'subscribed' self . progress_subject . notify () def _eval_cost ( self ): \"\"\"Evaluate Total (Style + Constent) Cost\"\"\" # pass cost objects in session to evaluate them Jt , Jc , Js = self . session_runner . run ( [ self . nn_cost_builder . cost , self . nn_cost_builder . content_cost , self . nn_cost_builder . style_cost , ] ) return Jt , Jc , Js def _print_cost ( self , iteration_index ): weighted_Jc = self . nn_cost_builder . content_cost_weight * self . Jc weighted_Js = self . nn_cost_builder . style_cost_weight * self . Js print ( f \" Iteration: { iteration_index } \\n \" f \" Jc + Js = { self . Js + self . Jc } \\n \" f \" Total Cost : { self . Jt } \\n \" f \" a * Jc + b * Js = { weighted_Jc + weighted_Js } \\n \" f \" Weighted Content Cost : { weighted_Jc } \\n \" f \" Weighted Style Cost : { weighted_Js } \\n \" f \" Content cost : { self . Jc } \\n \" f \" Style cost : { self . Js } \\n \" )","title":"NSTAlgorithmRunner"},{"location":"reference/artificial_artwork/nst_tf_algorithm/#artificial_artwork.nst_tf_algorithm.NeuralNetBuilder","text":"Configure a pretrained image model to facilitate nst algorithm. Source code in src/artificial_artwork/nst_tf_algorithm.py 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 @attr . s class NeuralNetBuilder : \"\"\"Configure a pretrained image model to facilitate nst algorithm.\"\"\" model = attr . ib () session = attr . ib () output_neurons = attr . ib ( init = False , default = None ) a_C = attr . ib ( init = False , default = None ) a_G = attr . ib ( init = False , default = None ) def assign_input ( self , image ): # Assign the content image to be the input of the VGG model. self . session . run ( self . model [ \"input\" ] . assign ( image )) def build_activations ( self , content_image , model_layer_id : str ): self . assign_input ( content_image ) self . _set_output ( model_layer_id ) self . _setup_activations () def _set_output ( self , model_layer_id : str ): # Select the output tensor of a Neural Network layer self . output_neurons = self . model [ model_layer_id ] def _setup_activations ( self ): # Set a_C to be the hidden layer activation from the layer we have selected # Remember we have re-constructed the pretrained model Network by now. # And we have selected in the NetworkDesign a layer that will bee the # 'Output Layer'. Here we say that the Image Model will be modeling the # Content of the G Image as the output of that selected Output Layer. self . a_C = self . session . run ( self . output_neurons ) # Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that # when we run the session, this will be the activations drawn from the appropriate layer, # with G as input. self . a_G = self . output_neurons","title":"NeuralNetBuilder"},{"location":"reference/artificial_artwork/styling_observer/","text":"StylingObserver Bases: Observer Store a snapshot of the image under construction. Parameters: Name Type Description Default save_on_disk_callback Callable [[ str , NDArray ], None] Callback required convert_to_unit8 Callable [[ NDArray ], NDArray ] Callback required Source code in src/artificial_artwork/styling_observer.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @define class StylingObserver ( Observer ): \"\"\"Store a snapshot of the image under construction. Args: save_on_disk_callback (Callable[[str, npt.NDArray], None]): Callback convert_to_unit8 (Callable[[npt.NDArray], npt.NDArray]): Callback \"\"\" save_on_disk_callback : Callable [[ str , npt . NDArray ], None ] convert_to_unit8 : Callable [[ npt . NDArray ], npt . NDArray ] max_iterations : int get_file_name : Callable [[], str ] = field ( default = Factory ( lambda self : build_default_get_file_name ( self . max_iterations ), takes_self = True ) ) def update ( self , * args , ** kwargs ): output_dir = args [ 0 ] . state . output_path content_image_path = args [ 0 ] . state . content_image_path style_image_path = args [ 0 ] . state . style_image_path iterations_completed = args [ 0 ] . state . metrics [ \"iterations\" ] matrix = args [ 0 ] . state . matrix # Future work: Impelement handling of the \"request to persist\" with a # chain of responsibility design pattern. It suits this case since we # do not know how many checks and/or image transformation will be # required before saving on disk output_file_path = os . path . join ( output_dir , self . get_file_name ( content_image_path , style_image_path , iterations_completed ), ) # if we have shape of form (1, Width, Height, Number_of_Color_Channels) if matrix . ndim == 4 and matrix . shape [ 0 ] == 1 : # reshape to (Width, Height, Number_of_Color_Channels) matrix = np . reshape ( matrix , tuple ( matrix . shape [ 1 :])) if str ( matrix . dtype ) != \"uint8\" : matrix = self . convert_to_unit8 ( matrix ) if np . nanmin ( matrix ) < 0 : raise ImageDataValueError ( \"Generated Image has pixel(s) with negative values.\" ) if np . nanmax ( matrix ) >= np . power ( 2.0 , 8 ): raise ImageDataValueError ( \"Generated Image has pixel(s) with value >= 255.\" ) self . save_on_disk_callback ( matrix , output_file_path , save_format = \"png\" )","title":"styling_observer"},{"location":"reference/artificial_artwork/styling_observer/#artificial_artwork.styling_observer.StylingObserver","text":"Bases: Observer Store a snapshot of the image under construction. Parameters: Name Type Description Default save_on_disk_callback Callable [[ str , NDArray ], None] Callback required convert_to_unit8 Callable [[ NDArray ], NDArray ] Callback required Source code in src/artificial_artwork/styling_observer.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @define class StylingObserver ( Observer ): \"\"\"Store a snapshot of the image under construction. Args: save_on_disk_callback (Callable[[str, npt.NDArray], None]): Callback convert_to_unit8 (Callable[[npt.NDArray], npt.NDArray]): Callback \"\"\" save_on_disk_callback : Callable [[ str , npt . NDArray ], None ] convert_to_unit8 : Callable [[ npt . NDArray ], npt . NDArray ] max_iterations : int get_file_name : Callable [[], str ] = field ( default = Factory ( lambda self : build_default_get_file_name ( self . max_iterations ), takes_self = True ) ) def update ( self , * args , ** kwargs ): output_dir = args [ 0 ] . state . output_path content_image_path = args [ 0 ] . state . content_image_path style_image_path = args [ 0 ] . state . style_image_path iterations_completed = args [ 0 ] . state . metrics [ \"iterations\" ] matrix = args [ 0 ] . state . matrix # Future work: Impelement handling of the \"request to persist\" with a # chain of responsibility design pattern. It suits this case since we # do not know how many checks and/or image transformation will be # required before saving on disk output_file_path = os . path . join ( output_dir , self . get_file_name ( content_image_path , style_image_path , iterations_completed ), ) # if we have shape of form (1, Width, Height, Number_of_Color_Channels) if matrix . ndim == 4 and matrix . shape [ 0 ] == 1 : # reshape to (Width, Height, Number_of_Color_Channels) matrix = np . reshape ( matrix , tuple ( matrix . shape [ 1 :])) if str ( matrix . dtype ) != \"uint8\" : matrix = self . convert_to_unit8 ( matrix ) if np . nanmin ( matrix ) < 0 : raise ImageDataValueError ( \"Generated Image has pixel(s) with negative values.\" ) if np . nanmax ( matrix ) >= np . power ( 2.0 , 8 ): raise ImageDataValueError ( \"Generated Image has pixel(s) with value >= 255.\" ) self . save_on_disk_callback ( matrix , output_file_path , save_format = \"png\" )","title":"StylingObserver"},{"location":"reference/artificial_artwork/termination_condition_adapter/","text":"TerminationConditionAdapterClassFactory Acts as a proxy to the the 'class maker' function by returning a memoized class. Source code in src/artificial_artwork/termination_condition_adapter.py 72 73 74 75 76 77 78 79 class TerminationConditionAdapterClassFactory : \"\"\"Acts as a proxy to the the 'class maker' function by returning a memoized class.\"\"\" classes_pool = ObjectsPool ( new_class ) @classmethod def create ( cls , adapter_type : str ): return cls . classes_pool . get_object ( adapter_type )","title":"termination_condition_adapter"},{"location":"reference/artificial_artwork/termination_condition_adapter/#artificial_artwork.termination_condition_adapter.TerminationConditionAdapterClassFactory","text":"Acts as a proxy to the the 'class maker' function by returning a memoized class. Source code in src/artificial_artwork/termination_condition_adapter.py 72 73 74 75 76 77 78 79 class TerminationConditionAdapterClassFactory : \"\"\"Acts as a proxy to the the 'class maker' function by returning a memoized class.\"\"\" classes_pool = ObjectsPool ( new_class ) @classmethod def create ( cls , adapter_type : str ): return cls . classes_pool . get_object ( adapter_type )","title":"TerminationConditionAdapterClassFactory"},{"location":"reference/artificial_artwork/termination_condition_adapter_factory/","text":"","title":"termination_condition_adapter_factory"},{"location":"reference/artificial_artwork/tf_session_runner/","text":"TensorflowSessionRunner Bases: Proxy Source code in src/artificial_artwork/tf_session_runner.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 class TensorflowSessionRunner ( Proxy ): def __init__ ( self , real_subject ) -> None : super () . __init__ ( real_subject ) # self._proxy_subject IS a reference to an # TensorflowSessionRun nerSubject instance self . args_history : List [ str ] = [] def run ( self , * args , ** kwargs ): \"\"\"# Using the `close()` method. sess = tf.compat.v1.Session() sess.run(...) sess.close() OR # Using the context manager. with tf.compat.v1.Session() as sess: sess.run(...) \"\"\" session_run_callable = self . _proxy_subject . run args_str = f \"[ { ', ' . join (( str ( _ ) for _ in args )) } ]\" kwargs_str = f \"[ { ', ' . join (( f ' { k } = { v } ' for k , v in kwargs . items ())) } ]\" self . args_history . append ( f \"ARGS: { args_str } , KWARGS: { kwargs_str } \" ) try : return session_run_callable ( * args , ** kwargs ) except Exception as tensorflow_error : raise TensorflowSessionRunError ( \"Tensorflow error occured, when\" f \"running session with input args { args_str } and kwargs { kwargs_str } \" ) from tensorflow_error @property def session ( self ): return self . _proxy_subject . interactive_session @classmethod def with_default_graph_reset ( cls ): tf . compat . v1 . reset_default_graph () tf . compat . v1 . disable_eager_execution () return TensorflowSessionRunner ( TensorflowSessionRunnerSubject ( tf . compat . v1 . InteractiveSession ()) ) run ( * args , ** kwargs ) Using the close() method. sess = tf.compat.v1.Session() sess.run(...) sess.close() OR Using the context manager. with tf.compat.v1.Session() as sess: sess.run(...) Source code in src/artificial_artwork/tf_session_runner.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def run ( self , * args , ** kwargs ): \"\"\"# Using the `close()` method. sess = tf.compat.v1.Session() sess.run(...) sess.close() OR # Using the context manager. with tf.compat.v1.Session() as sess: sess.run(...) \"\"\" session_run_callable = self . _proxy_subject . run args_str = f \"[ { ', ' . join (( str ( _ ) for _ in args )) } ]\" kwargs_str = f \"[ { ', ' . join (( f ' { k } = { v } ' for k , v in kwargs . items ())) } ]\" self . args_history . append ( f \"ARGS: { args_str } , KWARGS: { kwargs_str } \" ) try : return session_run_callable ( * args , ** kwargs ) except Exception as tensorflow_error : raise TensorflowSessionRunError ( \"Tensorflow error occured, when\" f \"running session with input args { args_str } and kwargs { kwargs_str } \" ) from tensorflow_error","title":"tf_session_runner"},{"location":"reference/artificial_artwork/tf_session_runner/#artificial_artwork.tf_session_runner.TensorflowSessionRunner","text":"Bases: Proxy Source code in src/artificial_artwork/tf_session_runner.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 class TensorflowSessionRunner ( Proxy ): def __init__ ( self , real_subject ) -> None : super () . __init__ ( real_subject ) # self._proxy_subject IS a reference to an # TensorflowSessionRun nerSubject instance self . args_history : List [ str ] = [] def run ( self , * args , ** kwargs ): \"\"\"# Using the `close()` method. sess = tf.compat.v1.Session() sess.run(...) sess.close() OR # Using the context manager. with tf.compat.v1.Session() as sess: sess.run(...) \"\"\" session_run_callable = self . _proxy_subject . run args_str = f \"[ { ', ' . join (( str ( _ ) for _ in args )) } ]\" kwargs_str = f \"[ { ', ' . join (( f ' { k } = { v } ' for k , v in kwargs . items ())) } ]\" self . args_history . append ( f \"ARGS: { args_str } , KWARGS: { kwargs_str } \" ) try : return session_run_callable ( * args , ** kwargs ) except Exception as tensorflow_error : raise TensorflowSessionRunError ( \"Tensorflow error occured, when\" f \"running session with input args { args_str } and kwargs { kwargs_str } \" ) from tensorflow_error @property def session ( self ): return self . _proxy_subject . interactive_session @classmethod def with_default_graph_reset ( cls ): tf . compat . v1 . reset_default_graph () tf . compat . v1 . disable_eager_execution () return TensorflowSessionRunner ( TensorflowSessionRunnerSubject ( tf . compat . v1 . InteractiveSession ()) )","title":"TensorflowSessionRunner"},{"location":"reference/artificial_artwork/tf_session_runner/#artificial_artwork.tf_session_runner.TensorflowSessionRunner.run","text":"","title":"run()"},{"location":"reference/artificial_artwork/tf_session_runner/#artificial_artwork.tf_session_runner.TensorflowSessionRunner.run--using-the-close-method","text":"sess = tf.compat.v1.Session() sess.run(...) sess.close() OR","title":"Using the close() method."},{"location":"reference/artificial_artwork/tf_session_runner/#artificial_artwork.tf_session_runner.TensorflowSessionRunner.run--using-the-context-manager","text":"with tf.compat.v1.Session() as sess: sess.run(...) Source code in src/artificial_artwork/tf_session_runner.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def run ( self , * args , ** kwargs ): \"\"\"# Using the `close()` method. sess = tf.compat.v1.Session() sess.run(...) sess.close() OR # Using the context manager. with tf.compat.v1.Session() as sess: sess.run(...) \"\"\" session_run_callable = self . _proxy_subject . run args_str = f \"[ { ', ' . join (( str ( _ ) for _ in args )) } ]\" kwargs_str = f \"[ { ', ' . join (( f ' { k } = { v } ' for k , v in kwargs . items ())) } ]\" self . args_history . append ( f \"ARGS: { args_str } , KWARGS: { kwargs_str } \" ) try : return session_run_callable ( * args , ** kwargs ) except Exception as tensorflow_error : raise TensorflowSessionRunError ( \"Tensorflow error occured, when\" f \"running session with input args { args_str } and kwargs { kwargs_str } \" ) from tensorflow_error","title":"Using the context manager."},{"location":"reference/artificial_artwork/utils/","text":"load_pretrained_model_functions () Load Pretrained Model Interface Implementations. Source code in src/artificial_artwork/utils.py 9 10 11 12 13 14 15 def load_pretrained_model_functions (): \"\"\"Load Pretrained Model Interface Implementations.\"\"\" # future work: discover dynamically the modules inside the pre_trained_model # package from .pre_trained_models import vgg return vgg","title":"utils"},{"location":"reference/artificial_artwork/utils/#artificial_artwork.utils.load_pretrained_model_functions","text":"Load Pretrained Model Interface Implementations. Source code in src/artificial_artwork/utils.py 9 10 11 12 13 14 15 def load_pretrained_model_functions (): \"\"\"Load Pretrained Model Interface Implementations.\"\"\" # future work: discover dynamically the modules inside the pre_trained_model # package from .pre_trained_models import vgg return vgg","title":"load_pretrained_model_functions()"},{"location":"reference/artificial_artwork/image/","text":"noisy ( image , ratio , seed = None ) Generates a noisy image by adding random noise to the content_image Source code in src/artificial_artwork/image/image_operations.py 120 121 122 123 124 125 126 127 128 129 130 131 132 def noisy ( image : NDArray , ratio : float , seed : int = None , ) -> NDArray : \"\"\"Generates a noisy image by adding random noise to the content_image\"\"\" if ratio < 0 or 1 < ratio : raise InvalidRatioError ( \"Expected a ratio value x such that 0 <= x <= 1\" ) noise_image = np . random . uniform ( - 20 , 20 , image . shape ) . astype ( \"float32\" ) # Set the input_image to be a weighted average of the content_image and a noise_image return noise_image * ratio + image * ( 1 - ratio ) subtract ( image , array ) Normalize the input image. Parameters: Name Type Description Default image NDArray [description] required Raises: Type Description ShapeMissmatchError in case of ValueError due to numpy broadcasting failing Returns: Name Type Description NDArray NDArray [description] Source code in src/artificial_artwork/image/image_operations.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def subtract ( image : NDArray , array : NDArray ) -> NDArray : \"\"\"Normalize the input image. Args: image (NDArray): [description] Raises: ShapeMissmatchError: in case of ValueError due to numpy broadcasting failing Returns: NDArray: [description] \"\"\" try : return image - array except ValueError as numpy_broadcast_error : raise ShapeMissmatchError ( \"Expected arrays with matching shapes.\" ) from numpy_broadcast_error","title":"image"},{"location":"reference/artificial_artwork/image/#artificial_artwork.image.noisy","text":"Generates a noisy image by adding random noise to the content_image Source code in src/artificial_artwork/image/image_operations.py 120 121 122 123 124 125 126 127 128 129 130 131 132 def noisy ( image : NDArray , ratio : float , seed : int = None , ) -> NDArray : \"\"\"Generates a noisy image by adding random noise to the content_image\"\"\" if ratio < 0 or 1 < ratio : raise InvalidRatioError ( \"Expected a ratio value x such that 0 <= x <= 1\" ) noise_image = np . random . uniform ( - 20 , 20 , image . shape ) . astype ( \"float32\" ) # Set the input_image to be a weighted average of the content_image and a noise_image return noise_image * ratio + image * ( 1 - ratio )","title":"noisy()"},{"location":"reference/artificial_artwork/image/#artificial_artwork.image.subtract","text":"Normalize the input image. Parameters: Name Type Description Default image NDArray [description] required Raises: Type Description ShapeMissmatchError in case of ValueError due to numpy broadcasting failing Returns: Name Type Description NDArray NDArray [description] Source code in src/artificial_artwork/image/image_operations.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def subtract ( image : NDArray , array : NDArray ) -> NDArray : \"\"\"Normalize the input image. Args: image (NDArray): [description] Raises: ShapeMissmatchError: in case of ValueError due to numpy broadcasting failing Returns: NDArray: [description] \"\"\" try : return image - array except ValueError as numpy_broadcast_error : raise ShapeMissmatchError ( \"Expected arrays with matching shapes.\" ) from numpy_broadcast_error","title":"subtract()"},{"location":"reference/artificial_artwork/image/image/","text":"Image An image loaded into memory, represented as a multidimension mathematical matrix/array. The 'file_path' attribute indicates a file in the disk that corresponds to the matrix Parameters: Name Type Description Default file_path str the file in disk that the image was loaded from required matrix NDArray the loaded image as mathmatical array/matrix required Source code in src/artificial_artwork/image/image.py 5 6 7 8 9 10 11 12 13 14 15 16 17 @attr . s class Image : \"\"\"An image loaded into memory, represented as a multidimension mathematical matrix/array. The 'file_path' attribute indicates a file in the disk that corresponds to the matrix Args: file_path (str): the file in disk that the image was loaded from matrix (NDArray): the loaded image as mathmatical array/matrix \"\"\" file_path : str = attr . ib () matrix : NDArray = attr . ib ( default = None )","title":"image"},{"location":"reference/artificial_artwork/image/image/#artificial_artwork.image.image.Image","text":"An image loaded into memory, represented as a multidimension mathematical matrix/array. The 'file_path' attribute indicates a file in the disk that corresponds to the matrix Parameters: Name Type Description Default file_path str the file in disk that the image was loaded from required matrix NDArray the loaded image as mathmatical array/matrix required Source code in src/artificial_artwork/image/image.py 5 6 7 8 9 10 11 12 13 14 15 16 17 @attr . s class Image : \"\"\"An image loaded into memory, represented as a multidimension mathematical matrix/array. The 'file_path' attribute indicates a file in the disk that corresponds to the matrix Args: file_path (str): the file in disk that the image was loaded from matrix (NDArray): the loaded image as mathmatical array/matrix \"\"\" file_path : str = attr . ib () matrix : NDArray = attr . ib ( default = None )","title":"Image"},{"location":"reference/artificial_artwork/image/image_factory/","text":"","title":"image_factory"},{"location":"reference/artificial_artwork/image/image_operations/","text":"ImageNoiseAdder Add random noise to an image, given a ratio and optional seed number. If seed is passed other than None, then the instance is configued with a seeded random number generator (RNG). Otherwise, the instance is configured with a non-seeded RNG. Source code in src/artificial_artwork/image/image_operations.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 @define ( slots = True , kw_only = True ) class ImageNoiseAdder : \"\"\"Add random noise to an image, given a ratio and optional seed number. If seed is passed other than None, then the instance is configued with a seeded random number generator (RNG). Otherwise, the instance is configured with a non-seeded RNG. \"\"\" seed : t . Union [ int , None ] = field ( default = None ) min_pixel_value : int = field ( default =- 20 ) max_pixel_value : int = field ( default = 20 ) # Private Attributes _default_rng : RandomArrayGenerator = field ( init = False , default = Factory ( lambda self : self . _create_rng ( self . seed , ), takes_self = True , ), ) def __call__ ( self , image : NDArray , ratio : float , seed : t . Union [ int , None ] = None ) -> NDArray : \"\"\"Generates a noisy image by adding random noise to the content_image If instance has been configured without Seed, and you wish to continue using the same RNG, then pass no seed. If instance has been configured with Seed, and you wish to continue using the same RNG, then pass no seed. If instance has been configured with Seed, and you wish to use a new RNG, then pass a new seed. \"\"\" if ratio < 0 or 1 < ratio : raise InvalidRatioError ( \"Expected a ratio value x such that 0 <= x <= 1\" ) if seed is not None : # user want to re-configure new RNG Stochastic Process # with a provided seed self . _default_rng = self . _create_rng ( seed ) # if seed is None: # user wants to continue sampling from the configured RNG # we continue using the 'default Stochastic Process' for sampling random_noise_pixel_array = self . _default_rng ( # numpy float32 array self . min_pixel_value , self . max_pixel_value , image . shape , ) # Set the input_image to be a weighted average of the content_image and a noise_image return random_noise_pixel_array * ratio + image * ( 1 - ratio ) # Private methods @staticmethod def _create_rng ( seed : t . Union [ int , None ]) -> RandomArrayGenerator : \"\"\"Handle request to re-configure RNG potentially seeded with provided seed.\"\"\" _rng = np . random . default_rng ( seed = seed ) rng : RandomArrayGenerator = _rng . uniform def _rng_float32 ( minimum_pixel_value : int , maximum_pixel_value : int , pixel_array_shape : t . Tuple [ int , ... ], ) -> NDArray : return rng ( minimum_pixel_value , maximum_pixel_value , pixel_array_shape , ) . astype ( \"float32\" ) return _rng_float32 __call__ ( image , ratio , seed = None ) Generates a noisy image by adding random noise to the content_image If instance has been configured without Seed, and you wish to continue using the same RNG, then pass no seed. If instance has been configured with Seed, and you wish to continue using the same RNG, then pass no seed. If instance has been configured with Seed, and you wish to use a new RNG, then pass a new seed. Source code in src/artificial_artwork/image/image_operations.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def __call__ ( self , image : NDArray , ratio : float , seed : t . Union [ int , None ] = None ) -> NDArray : \"\"\"Generates a noisy image by adding random noise to the content_image If instance has been configured without Seed, and you wish to continue using the same RNG, then pass no seed. If instance has been configured with Seed, and you wish to continue using the same RNG, then pass no seed. If instance has been configured with Seed, and you wish to use a new RNG, then pass a new seed. \"\"\" if ratio < 0 or 1 < ratio : raise InvalidRatioError ( \"Expected a ratio value x such that 0 <= x <= 1\" ) if seed is not None : # user want to re-configure new RNG Stochastic Process # with a provided seed self . _default_rng = self . _create_rng ( seed ) # if seed is None: # user wants to continue sampling from the configured RNG # we continue using the 'default Stochastic Process' for sampling random_noise_pixel_array = self . _default_rng ( # numpy float32 array self . min_pixel_value , self . max_pixel_value , image . shape , ) # Set the input_image to be a weighted average of the content_image and a noise_image return random_noise_pixel_array * ratio + image * ( 1 - ratio ) noisy ( image , ratio , seed = None ) Generates a noisy image by adding random noise to the content_image Source code in src/artificial_artwork/image/image_operations.py 120 121 122 123 124 125 126 127 128 129 130 131 132 def noisy ( image : NDArray , ratio : float , seed : int = None , ) -> NDArray : \"\"\"Generates a noisy image by adding random noise to the content_image\"\"\" if ratio < 0 or 1 < ratio : raise InvalidRatioError ( \"Expected a ratio value x such that 0 <= x <= 1\" ) noise_image = np . random . uniform ( - 20 , 20 , image . shape ) . astype ( \"float32\" ) # Set the input_image to be a weighted average of the content_image and a noise_image return noise_image * ratio + image * ( 1 - ratio ) subtract ( image , array ) Normalize the input image. Parameters: Name Type Description Default image NDArray [description] required Raises: Type Description ShapeMissmatchError in case of ValueError due to numpy broadcasting failing Returns: Name Type Description NDArray NDArray [description] Source code in src/artificial_artwork/image/image_operations.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def subtract ( image : NDArray , array : NDArray ) -> NDArray : \"\"\"Normalize the input image. Args: image (NDArray): [description] Raises: ShapeMissmatchError: in case of ValueError due to numpy broadcasting failing Returns: NDArray: [description] \"\"\" try : return image - array except ValueError as numpy_broadcast_error : raise ShapeMissmatchError ( \"Expected arrays with matching shapes.\" ) from numpy_broadcast_error","title":"image_operations"},{"location":"reference/artificial_artwork/image/image_operations/#artificial_artwork.image.image_operations.ImageNoiseAdder","text":"Add random noise to an image, given a ratio and optional seed number. If seed is passed other than None, then the instance is configued with a seeded random number generator (RNG). Otherwise, the instance is configured with a non-seeded RNG. Source code in src/artificial_artwork/image/image_operations.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 @define ( slots = True , kw_only = True ) class ImageNoiseAdder : \"\"\"Add random noise to an image, given a ratio and optional seed number. If seed is passed other than None, then the instance is configued with a seeded random number generator (RNG). Otherwise, the instance is configured with a non-seeded RNG. \"\"\" seed : t . Union [ int , None ] = field ( default = None ) min_pixel_value : int = field ( default =- 20 ) max_pixel_value : int = field ( default = 20 ) # Private Attributes _default_rng : RandomArrayGenerator = field ( init = False , default = Factory ( lambda self : self . _create_rng ( self . seed , ), takes_self = True , ), ) def __call__ ( self , image : NDArray , ratio : float , seed : t . Union [ int , None ] = None ) -> NDArray : \"\"\"Generates a noisy image by adding random noise to the content_image If instance has been configured without Seed, and you wish to continue using the same RNG, then pass no seed. If instance has been configured with Seed, and you wish to continue using the same RNG, then pass no seed. If instance has been configured with Seed, and you wish to use a new RNG, then pass a new seed. \"\"\" if ratio < 0 or 1 < ratio : raise InvalidRatioError ( \"Expected a ratio value x such that 0 <= x <= 1\" ) if seed is not None : # user want to re-configure new RNG Stochastic Process # with a provided seed self . _default_rng = self . _create_rng ( seed ) # if seed is None: # user wants to continue sampling from the configured RNG # we continue using the 'default Stochastic Process' for sampling random_noise_pixel_array = self . _default_rng ( # numpy float32 array self . min_pixel_value , self . max_pixel_value , image . shape , ) # Set the input_image to be a weighted average of the content_image and a noise_image return random_noise_pixel_array * ratio + image * ( 1 - ratio ) # Private methods @staticmethod def _create_rng ( seed : t . Union [ int , None ]) -> RandomArrayGenerator : \"\"\"Handle request to re-configure RNG potentially seeded with provided seed.\"\"\" _rng = np . random . default_rng ( seed = seed ) rng : RandomArrayGenerator = _rng . uniform def _rng_float32 ( minimum_pixel_value : int , maximum_pixel_value : int , pixel_array_shape : t . Tuple [ int , ... ], ) -> NDArray : return rng ( minimum_pixel_value , maximum_pixel_value , pixel_array_shape , ) . astype ( \"float32\" ) return _rng_float32","title":"ImageNoiseAdder"},{"location":"reference/artificial_artwork/image/image_operations/#artificial_artwork.image.image_operations.ImageNoiseAdder.__call__","text":"Generates a noisy image by adding random noise to the content_image If instance has been configured without Seed, and you wish to continue using the same RNG, then pass no seed. If instance has been configured with Seed, and you wish to continue using the same RNG, then pass no seed. If instance has been configured with Seed, and you wish to use a new RNG, then pass a new seed. Source code in src/artificial_artwork/image/image_operations.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def __call__ ( self , image : NDArray , ratio : float , seed : t . Union [ int , None ] = None ) -> NDArray : \"\"\"Generates a noisy image by adding random noise to the content_image If instance has been configured without Seed, and you wish to continue using the same RNG, then pass no seed. If instance has been configured with Seed, and you wish to continue using the same RNG, then pass no seed. If instance has been configured with Seed, and you wish to use a new RNG, then pass a new seed. \"\"\" if ratio < 0 or 1 < ratio : raise InvalidRatioError ( \"Expected a ratio value x such that 0 <= x <= 1\" ) if seed is not None : # user want to re-configure new RNG Stochastic Process # with a provided seed self . _default_rng = self . _create_rng ( seed ) # if seed is None: # user wants to continue sampling from the configured RNG # we continue using the 'default Stochastic Process' for sampling random_noise_pixel_array = self . _default_rng ( # numpy float32 array self . min_pixel_value , self . max_pixel_value , image . shape , ) # Set the input_image to be a weighted average of the content_image and a noise_image return random_noise_pixel_array * ratio + image * ( 1 - ratio )","title":"__call__()"},{"location":"reference/artificial_artwork/image/image_operations/#artificial_artwork.image.image_operations.noisy","text":"Generates a noisy image by adding random noise to the content_image Source code in src/artificial_artwork/image/image_operations.py 120 121 122 123 124 125 126 127 128 129 130 131 132 def noisy ( image : NDArray , ratio : float , seed : int = None , ) -> NDArray : \"\"\"Generates a noisy image by adding random noise to the content_image\"\"\" if ratio < 0 or 1 < ratio : raise InvalidRatioError ( \"Expected a ratio value x such that 0 <= x <= 1\" ) noise_image = np . random . uniform ( - 20 , 20 , image . shape ) . astype ( \"float32\" ) # Set the input_image to be a weighted average of the content_image and a noise_image return noise_image * ratio + image * ( 1 - ratio )","title":"noisy()"},{"location":"reference/artificial_artwork/image/image_operations/#artificial_artwork.image.image_operations.subtract","text":"Normalize the input image. Parameters: Name Type Description Default image NDArray [description] required Raises: Type Description ShapeMissmatchError in case of ValueError due to numpy broadcasting failing Returns: Name Type Description NDArray NDArray [description] Source code in src/artificial_artwork/image/image_operations.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def subtract ( image : NDArray , array : NDArray ) -> NDArray : \"\"\"Normalize the input image. Args: image (NDArray): [description] Raises: ShapeMissmatchError: in case of ValueError due to numpy broadcasting failing Returns: NDArray: [description] \"\"\" try : return image - array except ValueError as numpy_broadcast_error : raise ShapeMissmatchError ( \"Expected arrays with matching shapes.\" ) from numpy_broadcast_error","title":"subtract()"},{"location":"reference/artificial_artwork/image/image_processor/","text":"","title":"image_processor"},{"location":"reference/artificial_artwork/pre_trained_models/","text":"","title":"pre_trained_models"},{"location":"reference/artificial_artwork/pre_trained_models/vgg/","text":"","title":"vgg"},{"location":"reference/artificial_artwork/pretrained_model/","text":"Modelhandler Bases: ModelHandlerInterface Handle Parameters: Name Type Description Default ModelHandlerInterface [ type ] [description] required Raises: Type Description NoImageModelSpesifiedError [description] Returns: Type Description Source code in src/artificial_artwork/pretrained_model/model_handler.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class Modelhandler ( ModelHandlerInterface ): \"\"\"Handle Args: ModelHandlerInterface ([type]): [description] Raises: NoImageModelSpesifiedError: [description] Returns: [type]: [description] \"\"\" _reporter : ReporterProtocol def __init__ ( self ): self . _reporter = None @property def reporter ( self ) -> ReporterProtocol : \"\"\"Reporter getter, which can return Layer Weights given a layer (str) ID Args: layers ([type]): [description] \"\"\" return self . _reporter @reporter . setter def reporter ( self , layers ) -> None : self . _reporter = self . _create_reporter ( layers ) def _create_reporter ( self , layers : NDArray ) -> ReporterProtocol : return ModelReporter ( self . model_routines . get_layers_dict ( layers ), self . model_routines . get_weights ) def load_model_layers ( self ) -> NDArray : layers = self . _load_model_layers () self . _reporter = self . _create_reporter ( layers ) return layers def _load_model_layers ( self ) -> NDArray : try : return self . model_routines . load_layers ( os . environ [ self . environment_variable ]) except KeyError as variable_not_found : raise NoImageModelSpesifiedError ( self . model_load_exception_text ) from variable_not_found reporter : ReporterProtocol property writable Reporter getter, which can return Layer Weights given a layer (str) ID Parameters: Name Type Description Default layers [ type ] [description] required","title":"pretrained_model"},{"location":"reference/artificial_artwork/pretrained_model/#artificial_artwork.pretrained_model.Modelhandler","text":"Bases: ModelHandlerInterface Handle Parameters: Name Type Description Default ModelHandlerInterface [ type ] [description] required Raises: Type Description NoImageModelSpesifiedError [description] Returns: Type Description Source code in src/artificial_artwork/pretrained_model/model_handler.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class Modelhandler ( ModelHandlerInterface ): \"\"\"Handle Args: ModelHandlerInterface ([type]): [description] Raises: NoImageModelSpesifiedError: [description] Returns: [type]: [description] \"\"\" _reporter : ReporterProtocol def __init__ ( self ): self . _reporter = None @property def reporter ( self ) -> ReporterProtocol : \"\"\"Reporter getter, which can return Layer Weights given a layer (str) ID Args: layers ([type]): [description] \"\"\" return self . _reporter @reporter . setter def reporter ( self , layers ) -> None : self . _reporter = self . _create_reporter ( layers ) def _create_reporter ( self , layers : NDArray ) -> ReporterProtocol : return ModelReporter ( self . model_routines . get_layers_dict ( layers ), self . model_routines . get_weights ) def load_model_layers ( self ) -> NDArray : layers = self . _load_model_layers () self . _reporter = self . _create_reporter ( layers ) return layers def _load_model_layers ( self ) -> NDArray : try : return self . model_routines . load_layers ( os . environ [ self . environment_variable ]) except KeyError as variable_not_found : raise NoImageModelSpesifiedError ( self . model_load_exception_text ) from variable_not_found","title":"Modelhandler"},{"location":"reference/artificial_artwork/pretrained_model/#artificial_artwork.pretrained_model.Modelhandler.reporter","text":"Reporter getter, which can return Layer Weights given a layer (str) ID Parameters: Name Type Description Default layers [ type ] [description] required","title":"reporter"},{"location":"reference/artificial_artwork/pretrained_model/layers_getter/","text":"","title":"layers_getter"},{"location":"reference/artificial_artwork/pretrained_model/model_handler/","text":"Modelhandler Bases: ModelHandlerInterface Handle Parameters: Name Type Description Default ModelHandlerInterface [ type ] [description] required Raises: Type Description NoImageModelSpesifiedError [description] Returns: Type Description Source code in src/artificial_artwork/pretrained_model/model_handler.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class Modelhandler ( ModelHandlerInterface ): \"\"\"Handle Args: ModelHandlerInterface ([type]): [description] Raises: NoImageModelSpesifiedError: [description] Returns: [type]: [description] \"\"\" _reporter : ReporterProtocol def __init__ ( self ): self . _reporter = None @property def reporter ( self ) -> ReporterProtocol : \"\"\"Reporter getter, which can return Layer Weights given a layer (str) ID Args: layers ([type]): [description] \"\"\" return self . _reporter @reporter . setter def reporter ( self , layers ) -> None : self . _reporter = self . _create_reporter ( layers ) def _create_reporter ( self , layers : NDArray ) -> ReporterProtocol : return ModelReporter ( self . model_routines . get_layers_dict ( layers ), self . model_routines . get_weights ) def load_model_layers ( self ) -> NDArray : layers = self . _load_model_layers () self . _reporter = self . _create_reporter ( layers ) return layers def _load_model_layers ( self ) -> NDArray : try : return self . model_routines . load_layers ( os . environ [ self . environment_variable ]) except KeyError as variable_not_found : raise NoImageModelSpesifiedError ( self . model_load_exception_text ) from variable_not_found reporter : ReporterProtocol property writable Reporter getter, which can return Layer Weights given a layer (str) ID Parameters: Name Type Description Default layers [ type ] [description] required","title":"model_handler"},{"location":"reference/artificial_artwork/pretrained_model/model_handler/#artificial_artwork.pretrained_model.model_handler.Modelhandler","text":"Bases: ModelHandlerInterface Handle Parameters: Name Type Description Default ModelHandlerInterface [ type ] [description] required Raises: Type Description NoImageModelSpesifiedError [description] Returns: Type Description Source code in src/artificial_artwork/pretrained_model/model_handler.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class Modelhandler ( ModelHandlerInterface ): \"\"\"Handle Args: ModelHandlerInterface ([type]): [description] Raises: NoImageModelSpesifiedError: [description] Returns: [type]: [description] \"\"\" _reporter : ReporterProtocol def __init__ ( self ): self . _reporter = None @property def reporter ( self ) -> ReporterProtocol : \"\"\"Reporter getter, which can return Layer Weights given a layer (str) ID Args: layers ([type]): [description] \"\"\" return self . _reporter @reporter . setter def reporter ( self , layers ) -> None : self . _reporter = self . _create_reporter ( layers ) def _create_reporter ( self , layers : NDArray ) -> ReporterProtocol : return ModelReporter ( self . model_routines . get_layers_dict ( layers ), self . model_routines . get_weights ) def load_model_layers ( self ) -> NDArray : layers = self . _load_model_layers () self . _reporter = self . _create_reporter ( layers ) return layers def _load_model_layers ( self ) -> NDArray : try : return self . model_routines . load_layers ( os . environ [ self . environment_variable ]) except KeyError as variable_not_found : raise NoImageModelSpesifiedError ( self . model_load_exception_text ) from variable_not_found","title":"Modelhandler"},{"location":"reference/artificial_artwork/pretrained_model/model_handler/#artificial_artwork.pretrained_model.model_handler.Modelhandler.reporter","text":"Reporter getter, which can return Layer Weights given a layer (str) ID Parameters: Name Type Description Default layers [ type ] [description] required","title":"reporter"},{"location":"reference/artificial_artwork/pretrained_model/model_handler_interface/","text":"","title":"model_handler_interface"},{"location":"reference/artificial_artwork/pretrained_model/model_routines/","text":"This modules defines the interface which must be implemented in order to utilize a pretrained model and its weights PretrainedModelRoutines Bases: ABC Set of routines that are required in order to use a pretrained model for nst. Source code in src/artificial_artwork/pretrained_model/model_routines.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 class PretrainedModelRoutines ( ABC ): \"\"\"Set of routines that are required in order to use a pretrained model for nst.\"\"\" @abstractmethod def load_layers ( self , file_path : str ) -> NDArray : \"\"\"Load a pretrained model from disk. Loads the model parameters, given the path to a file in the disk, that indicated where the pretrained model is. Args: file_path (str): the path corresponding to a file in the disk Returns: NDArray: the model parameters as a numpy array \"\"\" raise NotImplementedError @abstractmethod def get_id ( self , layer : NDArray ) -> str : \"\"\"Get the id of a model's network layer. The pretrained model being a neural network has a specific architecture and each layer should a unique string id that one can reference it. Args: layer (NDArray): the layer of a pretrained neural network model Returns: str: the layer id \"\"\" raise NotImplementedError @abstractmethod def get_layers_dict ( self , layers : NDArray ) -> Dict [ str , NDArray ]: \"\"\"Get a dict mapping strings to pretrained model layers. Args: layers (NDArray): the pretrained model layers Returns: Dict[str, NDArray]: the dictionary mapping strings to layers \"\"\" raise NotImplementedError @abstractmethod def get_weights ( self , layer : NDArray ) -> Tuple [ NDArray , NDArray ]: \"\"\"Get the values of the weights of a given network layer. Each pretrained model network layer has \"learned\" certain parameters in the form of \"weights\" (ie weight matrices A and b in equation Ax + b). Call this method to get a tuple of the A and b mathematical matrices. Args: layer (NDArray): the layer of a pretrained neural network model Returns: Tuple[NDArray, NDArray]: the weights in matrix A and b \"\"\" raise NotImplementedError get_id ( layer ) abstractmethod Get the id of a model's network layer. The pretrained model being a neural network has a specific architecture and each layer should a unique string id that one can reference it. Parameters: Name Type Description Default layer NDArray the layer of a pretrained neural network model required Returns: Name Type Description str str the layer id Source code in src/artificial_artwork/pretrained_model/model_routines.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @abstractmethod def get_id ( self , layer : NDArray ) -> str : \"\"\"Get the id of a model's network layer. The pretrained model being a neural network has a specific architecture and each layer should a unique string id that one can reference it. Args: layer (NDArray): the layer of a pretrained neural network model Returns: str: the layer id \"\"\" raise NotImplementedError get_layers_dict ( layers ) abstractmethod Get a dict mapping strings to pretrained model layers. Parameters: Name Type Description Default layers NDArray the pretrained model layers required Returns: Type Description Dict [ str , NDArray ] Dict[str, NDArray]: the dictionary mapping strings to layers Source code in src/artificial_artwork/pretrained_model/model_routines.py 43 44 45 46 47 48 49 50 51 52 53 @abstractmethod def get_layers_dict ( self , layers : NDArray ) -> Dict [ str , NDArray ]: \"\"\"Get a dict mapping strings to pretrained model layers. Args: layers (NDArray): the pretrained model layers Returns: Dict[str, NDArray]: the dictionary mapping strings to layers \"\"\" raise NotImplementedError get_weights ( layer ) abstractmethod Get the values of the weights of a given network layer. Each pretrained model network layer has \"learned\" certain parameters in the form of \"weights\" (ie weight matrices A and b in equation Ax + b). Call this method to get a tuple of the A and b mathematical matrices. Parameters: Name Type Description Default layer NDArray the layer of a pretrained neural network model required Returns: Type Description Tuple [ NDArray , NDArray ] Tuple[NDArray, NDArray]: the weights in matrix A and b Source code in src/artificial_artwork/pretrained_model/model_routines.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 @abstractmethod def get_weights ( self , layer : NDArray ) -> Tuple [ NDArray , NDArray ]: \"\"\"Get the values of the weights of a given network layer. Each pretrained model network layer has \"learned\" certain parameters in the form of \"weights\" (ie weight matrices A and b in equation Ax + b). Call this method to get a tuple of the A and b mathematical matrices. Args: layer (NDArray): the layer of a pretrained neural network model Returns: Tuple[NDArray, NDArray]: the weights in matrix A and b \"\"\" raise NotImplementedError load_layers ( file_path ) abstractmethod Load a pretrained model from disk. Loads the model parameters, given the path to a file in the disk, that indicated where the pretrained model is. Parameters: Name Type Description Default file_path str the path corresponding to a file in the disk required Returns: Name Type Description NDArray NDArray the model parameters as a numpy array Source code in src/artificial_artwork/pretrained_model/model_routines.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @abstractmethod def load_layers ( self , file_path : str ) -> NDArray : \"\"\"Load a pretrained model from disk. Loads the model parameters, given the path to a file in the disk, that indicated where the pretrained model is. Args: file_path (str): the path corresponding to a file in the disk Returns: NDArray: the model parameters as a numpy array \"\"\" raise NotImplementedError","title":"model_routines"},{"location":"reference/artificial_artwork/pretrained_model/model_routines/#artificial_artwork.pretrained_model.model_routines.PretrainedModelRoutines","text":"Bases: ABC Set of routines that are required in order to use a pretrained model for nst. Source code in src/artificial_artwork/pretrained_model/model_routines.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 class PretrainedModelRoutines ( ABC ): \"\"\"Set of routines that are required in order to use a pretrained model for nst.\"\"\" @abstractmethod def load_layers ( self , file_path : str ) -> NDArray : \"\"\"Load a pretrained model from disk. Loads the model parameters, given the path to a file in the disk, that indicated where the pretrained model is. Args: file_path (str): the path corresponding to a file in the disk Returns: NDArray: the model parameters as a numpy array \"\"\" raise NotImplementedError @abstractmethod def get_id ( self , layer : NDArray ) -> str : \"\"\"Get the id of a model's network layer. The pretrained model being a neural network has a specific architecture and each layer should a unique string id that one can reference it. Args: layer (NDArray): the layer of a pretrained neural network model Returns: str: the layer id \"\"\" raise NotImplementedError @abstractmethod def get_layers_dict ( self , layers : NDArray ) -> Dict [ str , NDArray ]: \"\"\"Get a dict mapping strings to pretrained model layers. Args: layers (NDArray): the pretrained model layers Returns: Dict[str, NDArray]: the dictionary mapping strings to layers \"\"\" raise NotImplementedError @abstractmethod def get_weights ( self , layer : NDArray ) -> Tuple [ NDArray , NDArray ]: \"\"\"Get the values of the weights of a given network layer. Each pretrained model network layer has \"learned\" certain parameters in the form of \"weights\" (ie weight matrices A and b in equation Ax + b). Call this method to get a tuple of the A and b mathematical matrices. Args: layer (NDArray): the layer of a pretrained neural network model Returns: Tuple[NDArray, NDArray]: the weights in matrix A and b \"\"\" raise NotImplementedError","title":"PretrainedModelRoutines"},{"location":"reference/artificial_artwork/pretrained_model/model_routines/#artificial_artwork.pretrained_model.model_routines.PretrainedModelRoutines.get_id","text":"Get the id of a model's network layer. The pretrained model being a neural network has a specific architecture and each layer should a unique string id that one can reference it. Parameters: Name Type Description Default layer NDArray the layer of a pretrained neural network model required Returns: Name Type Description str str the layer id Source code in src/artificial_artwork/pretrained_model/model_routines.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @abstractmethod def get_id ( self , layer : NDArray ) -> str : \"\"\"Get the id of a model's network layer. The pretrained model being a neural network has a specific architecture and each layer should a unique string id that one can reference it. Args: layer (NDArray): the layer of a pretrained neural network model Returns: str: the layer id \"\"\" raise NotImplementedError","title":"get_id()"},{"location":"reference/artificial_artwork/pretrained_model/model_routines/#artificial_artwork.pretrained_model.model_routines.PretrainedModelRoutines.get_layers_dict","text":"Get a dict mapping strings to pretrained model layers. Parameters: Name Type Description Default layers NDArray the pretrained model layers required Returns: Type Description Dict [ str , NDArray ] Dict[str, NDArray]: the dictionary mapping strings to layers Source code in src/artificial_artwork/pretrained_model/model_routines.py 43 44 45 46 47 48 49 50 51 52 53 @abstractmethod def get_layers_dict ( self , layers : NDArray ) -> Dict [ str , NDArray ]: \"\"\"Get a dict mapping strings to pretrained model layers. Args: layers (NDArray): the pretrained model layers Returns: Dict[str, NDArray]: the dictionary mapping strings to layers \"\"\" raise NotImplementedError","title":"get_layers_dict()"},{"location":"reference/artificial_artwork/pretrained_model/model_routines/#artificial_artwork.pretrained_model.model_routines.PretrainedModelRoutines.get_weights","text":"Get the values of the weights of a given network layer. Each pretrained model network layer has \"learned\" certain parameters in the form of \"weights\" (ie weight matrices A and b in equation Ax + b). Call this method to get a tuple of the A and b mathematical matrices. Parameters: Name Type Description Default layer NDArray the layer of a pretrained neural network model required Returns: Type Description Tuple [ NDArray , NDArray ] Tuple[NDArray, NDArray]: the weights in matrix A and b Source code in src/artificial_artwork/pretrained_model/model_routines.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 @abstractmethod def get_weights ( self , layer : NDArray ) -> Tuple [ NDArray , NDArray ]: \"\"\"Get the values of the weights of a given network layer. Each pretrained model network layer has \"learned\" certain parameters in the form of \"weights\" (ie weight matrices A and b in equation Ax + b). Call this method to get a tuple of the A and b mathematical matrices. Args: layer (NDArray): the layer of a pretrained neural network model Returns: Tuple[NDArray, NDArray]: the weights in matrix A and b \"\"\" raise NotImplementedError","title":"get_weights()"},{"location":"reference/artificial_artwork/pretrained_model/model_routines/#artificial_artwork.pretrained_model.model_routines.PretrainedModelRoutines.load_layers","text":"Load a pretrained model from disk. Loads the model parameters, given the path to a file in the disk, that indicated where the pretrained model is. Parameters: Name Type Description Default file_path str the path corresponding to a file in the disk required Returns: Name Type Description NDArray NDArray the model parameters as a numpy array Source code in src/artificial_artwork/pretrained_model/model_routines.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @abstractmethod def load_layers ( self , file_path : str ) -> NDArray : \"\"\"Load a pretrained model from disk. Loads the model parameters, given the path to a file in the disk, that indicated where the pretrained model is. Args: file_path (str): the path corresponding to a file in the disk Returns: NDArray: the model parameters as a numpy array \"\"\" raise NotImplementedError","title":"load_layers()"},{"location":"reference/artificial_artwork/production_networks/","text":"NetworkDesign Define what Layers to use for a Neural Style Transfer (NST) Algorithm. Neural Style Transfer leverages the Layers of an already trained network (ie a VGG Image Model) to extract the style of an image. This class defines what Layers to use for this purpose. Instances of this class encapsulate the information required to define these Layers for the NST Algorithm. This information covers 2 aspects of NST: - the Style Layers - the Output Layer. Style Layers are the ones believed to model the Style the pretrained model has \"learned\" and are modeled by this class as a sequence of layer (str) IDS paired with a normalized weight. Output Layer is the layer used to compute the content loss. It is modeled by this class as a single layer (str) ID. This class is agnostic of the actual Neural Network used for the NST, so it can be used with any Neural Network. Thus, this class's constructor expects to receive a sequence of IDs (str) that represent the available/actual layers of the pretrained model. Parameters: Name Type Description Default network_layers Tuple [ str ] The available/actual layers of the required style_layers Tuple [ Tuple [ str , float ]] Sequence of layer (str) IDS required output_layer str The layer used to compute the content loss. required Source code in src/artificial_artwork/production_networks/__init__.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 @define class NetworkDesign : \"\"\"Define what Layers to use for a Neural Style Transfer (NST) Algorithm. Neural Style Transfer leverages the Layers of an already trained network (ie a VGG Image Model) to extract the style of an image. This class defines what Layers to use for this purpose. Instances of this class encapsulate the information required to define these Layers for the NST Algorithm. This information covers 2 aspects of NST: - the Style Layers - the Output Layer. Style Layers are the ones believed to model the Style the pretrained model has \"learned\" and are modeled by this class as a sequence of layer (str) IDS paired with a normalized weight. Output Layer is the layer used to compute the content loss. It is modeled by this class as a single layer (str) ID. This class is agnostic of the actual Neural Network used for the NST, so it can be used with any Neural Network. Thus, this class's constructor expects to receive a sequence of IDs (str) that represent the available/actual layers of the pretrained model. Args: network_layers (Tuple[str]): The available/actual layers of the pretrained model. style_layers (Tuple[Tuple[str, float]]): Sequence of layer (str) IDS paired with a normalized weight, selected as Style Layers. output_layer (str): The layer used to compute the content loss. \"\"\" # tuple of strings, ie ('conv1_1', 'conv1_2', 'avgpool1', 'conv2_1') network_layers : Tuple [ str ] style_layers : NSTLayersSelection = field ( converter = style_layers ) output_layer : str @classmethod def from_default_vgg ( cls ): from .image_model import LAYERS STYLE_LAYERS = ( ( \"conv1_1\" , 0.2 ), ( \"conv2_1\" , 0.2 ), ( \"conv3_1\" , 0.2 ), ( \"conv4_1\" , 0.2 ), ( \"conv5_1\" , 0.2 ), ) return NetworkDesign ( LAYERS , STYLE_LAYERS , \"conv4_2\" , )","title":"production_networks"},{"location":"reference/artificial_artwork/production_networks/#artificial_artwork.production_networks.NetworkDesign","text":"Define what Layers to use for a Neural Style Transfer (NST) Algorithm. Neural Style Transfer leverages the Layers of an already trained network (ie a VGG Image Model) to extract the style of an image. This class defines what Layers to use for this purpose. Instances of this class encapsulate the information required to define these Layers for the NST Algorithm. This information covers 2 aspects of NST: - the Style Layers - the Output Layer. Style Layers are the ones believed to model the Style the pretrained model has \"learned\" and are modeled by this class as a sequence of layer (str) IDS paired with a normalized weight. Output Layer is the layer used to compute the content loss. It is modeled by this class as a single layer (str) ID. This class is agnostic of the actual Neural Network used for the NST, so it can be used with any Neural Network. Thus, this class's constructor expects to receive a sequence of IDs (str) that represent the available/actual layers of the pretrained model. Parameters: Name Type Description Default network_layers Tuple [ str ] The available/actual layers of the required style_layers Tuple [ Tuple [ str , float ]] Sequence of layer (str) IDS required output_layer str The layer used to compute the content loss. required Source code in src/artificial_artwork/production_networks/__init__.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 @define class NetworkDesign : \"\"\"Define what Layers to use for a Neural Style Transfer (NST) Algorithm. Neural Style Transfer leverages the Layers of an already trained network (ie a VGG Image Model) to extract the style of an image. This class defines what Layers to use for this purpose. Instances of this class encapsulate the information required to define these Layers for the NST Algorithm. This information covers 2 aspects of NST: - the Style Layers - the Output Layer. Style Layers are the ones believed to model the Style the pretrained model has \"learned\" and are modeled by this class as a sequence of layer (str) IDS paired with a normalized weight. Output Layer is the layer used to compute the content loss. It is modeled by this class as a single layer (str) ID. This class is agnostic of the actual Neural Network used for the NST, so it can be used with any Neural Network. Thus, this class's constructor expects to receive a sequence of IDs (str) that represent the available/actual layers of the pretrained model. Args: network_layers (Tuple[str]): The available/actual layers of the pretrained model. style_layers (Tuple[Tuple[str, float]]): Sequence of layer (str) IDS paired with a normalized weight, selected as Style Layers. output_layer (str): The layer used to compute the content loss. \"\"\" # tuple of strings, ie ('conv1_1', 'conv1_2', 'avgpool1', 'conv2_1') network_layers : Tuple [ str ] style_layers : NSTLayersSelection = field ( converter = style_layers ) output_layer : str @classmethod def from_default_vgg ( cls ): from .image_model import LAYERS STYLE_LAYERS = ( ( \"conv1_1\" , 0.2 ), ( \"conv2_1\" , 0.2 ), ( \"conv3_1\" , 0.2 ), ( \"conv4_1\" , 0.2 ), ( \"conv5_1\" , 0.2 ), ) return NetworkDesign ( LAYERS , STYLE_LAYERS , \"conv4_2\" , )","title":"NetworkDesign"},{"location":"reference/artificial_artwork/production_networks/image_model/","text":"This module contains the high-level architecture design of our 'style model'. As 'style model' we define a neural network (represented as a mathematical graph) with several convolutional layers with weights extacted from a pretrained image model (ie the vgg19 model trained for the task of image classification on the imagenet dataset) and some average pooling layers with predefined weights. All weigths of the style model stay constants during optimization of the training objective (aka cost function). Here we only take the convolution layer weights and define several new AveragePooling. We opt for AveragePooling compared to MaxPooling, since it has been shown to yield better results.","title":"image_model"},{"location":"reference/artificial_artwork/production_networks/style_layer_selector/","text":"","title":"style_layer_selector"},{"location":"reference/artificial_artwork/style_model/","text":"","title":"style_model"},{"location":"reference/artificial_artwork/style_model/graph_builder/","text":"GraphBuilder Build an NST Style Network as a Compuational Graph of Tensor Operations. Provides 3 methods for building the graph input relu_conv_2d avg_pool Client code must first call the 'input' method to provide the input image specifications (ie width, height, color_channels), which is necessary for the first layer of the Graph. Instances of this class are stateful, so the order in which the methods are called matters. The 'input' method must be called first, followed by alternating calls to 'relu_conv_2d' and 'avg_pool' methods. The Graph is stored in the 'graph' instance attribute, which is a dict of layer_id to the layer's output tensor. Source code in src/artificial_artwork/style_model/graph_builder.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 class GraphBuilder : \"\"\"Build an NST Style Network as a Compuational Graph of Tensor Operations. Provides 3 methods for building the graph: - input - relu_conv_2d - avg_pool Client code must first call the 'input' method to provide the input image specifications (ie width, height, color_channels), which is necessary for the first layer of the Graph. Instances of this class are stateful, so the order in which the methods are called matters. The 'input' method must be called first, followed by alternating calls to 'relu_conv_2d' and 'avg_pool' methods. The Graph is stored in the 'graph' instance attribute, which is a dict of layer_id to the layer's output tensor. \"\"\" def __init__ ( self ): self . __init () def __init ( self ): self . graph = {} self . _prev_layer = None def _build_layer ( self , layer_id : str , layer ): self . graph [ layer_id ] = layer self . _prev_layer = layer return self def input ( self , image_specs ): self . __init () return self . _build_layer ( \"input\" , tf . Variable ( np . zeros ( ( 1 , image_specs . height , image_specs . width , image_specs . color_channels ) ), dtype = \"float32\" , ), ) def avg_pool ( self , layer_id : str ): return self . _build_layer ( layer_id , tf . nn . avg_pool ( self . _prev_layer , ksize = [ 1 , 2 , 2 , 1 ], strides = [ 1 , 2 , 2 , 1 ], padding = \"SAME\" ), ) def relu_conv_2d ( self , layer_id : str , layer_weights : Tuple [ NDArray , NDArray ]): \"\"\"A Relu wrapped around a convolutional layer. Will use the layer_id to find weight (for W and b matrices) values in the pretrained model (layer). Also uses the layer_id to as dict key to the output graph. \"\"\" W , b = layer_weights return self . _build_layer ( layer_id , tf . nn . relu ( self . _conv_2d ( W , b ))) def _conv_2d ( self , W : NDArray , b : NDArray ): W = tf . constant ( W ) b = tf . constant ( np . reshape ( b , ( b . size ))) return ( tf . compat . v1 . nn . conv2d ( self . _prev_layer , filter = W , strides = [ 1 , 1 , 1 , 1 ], padding = \"SAME\" ) + b ) relu_conv_2d ( layer_id , layer_weights ) A Relu wrapped around a convolutional layer. Will use the layer_id to find weight (for W and b matrices) values in the pretrained model (layer). Also uses the layer_id to as dict key to the output graph. Source code in src/artificial_artwork/style_model/graph_builder.py 60 61 62 63 64 65 66 67 68 69 def relu_conv_2d ( self , layer_id : str , layer_weights : Tuple [ NDArray , NDArray ]): \"\"\"A Relu wrapped around a convolutional layer. Will use the layer_id to find weight (for W and b matrices) values in the pretrained model (layer). Also uses the layer_id to as dict key to the output graph. \"\"\" W , b = layer_weights return self . _build_layer ( layer_id , tf . nn . relu ( self . _conv_2d ( W , b )))","title":"graph_builder"},{"location":"reference/artificial_artwork/style_model/graph_builder/#artificial_artwork.style_model.graph_builder.GraphBuilder","text":"Build an NST Style Network as a Compuational Graph of Tensor Operations. Provides 3 methods for building the graph input relu_conv_2d avg_pool Client code must first call the 'input' method to provide the input image specifications (ie width, height, color_channels), which is necessary for the first layer of the Graph. Instances of this class are stateful, so the order in which the methods are called matters. The 'input' method must be called first, followed by alternating calls to 'relu_conv_2d' and 'avg_pool' methods. The Graph is stored in the 'graph' instance attribute, which is a dict of layer_id to the layer's output tensor. Source code in src/artificial_artwork/style_model/graph_builder.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 class GraphBuilder : \"\"\"Build an NST Style Network as a Compuational Graph of Tensor Operations. Provides 3 methods for building the graph: - input - relu_conv_2d - avg_pool Client code must first call the 'input' method to provide the input image specifications (ie width, height, color_channels), which is necessary for the first layer of the Graph. Instances of this class are stateful, so the order in which the methods are called matters. The 'input' method must be called first, followed by alternating calls to 'relu_conv_2d' and 'avg_pool' methods. The Graph is stored in the 'graph' instance attribute, which is a dict of layer_id to the layer's output tensor. \"\"\" def __init__ ( self ): self . __init () def __init ( self ): self . graph = {} self . _prev_layer = None def _build_layer ( self , layer_id : str , layer ): self . graph [ layer_id ] = layer self . _prev_layer = layer return self def input ( self , image_specs ): self . __init () return self . _build_layer ( \"input\" , tf . Variable ( np . zeros ( ( 1 , image_specs . height , image_specs . width , image_specs . color_channels ) ), dtype = \"float32\" , ), ) def avg_pool ( self , layer_id : str ): return self . _build_layer ( layer_id , tf . nn . avg_pool ( self . _prev_layer , ksize = [ 1 , 2 , 2 , 1 ], strides = [ 1 , 2 , 2 , 1 ], padding = \"SAME\" ), ) def relu_conv_2d ( self , layer_id : str , layer_weights : Tuple [ NDArray , NDArray ]): \"\"\"A Relu wrapped around a convolutional layer. Will use the layer_id to find weight (for W and b matrices) values in the pretrained model (layer). Also uses the layer_id to as dict key to the output graph. \"\"\" W , b = layer_weights return self . _build_layer ( layer_id , tf . nn . relu ( self . _conv_2d ( W , b ))) def _conv_2d ( self , W : NDArray , b : NDArray ): W = tf . constant ( W ) b = tf . constant ( np . reshape ( b , ( b . size ))) return ( tf . compat . v1 . nn . conv2d ( self . _prev_layer , filter = W , strides = [ 1 , 1 , 1 , 1 ], padding = \"SAME\" ) + b )","title":"GraphBuilder"},{"location":"reference/artificial_artwork/style_model/graph_builder/#artificial_artwork.style_model.graph_builder.GraphBuilder.relu_conv_2d","text":"A Relu wrapped around a convolutional layer. Will use the layer_id to find weight (for W and b matrices) values in the pretrained model (layer). Also uses the layer_id to as dict key to the output graph. Source code in src/artificial_artwork/style_model/graph_builder.py 60 61 62 63 64 65 66 67 68 69 def relu_conv_2d ( self , layer_id : str , layer_weights : Tuple [ NDArray , NDArray ]): \"\"\"A Relu wrapped around a convolutional layer. Will use the layer_id to find weight (for W and b matrices) values in the pretrained model (layer). Also uses the layer_id to as dict key to the output graph. \"\"\" W , b = layer_weights return self . _build_layer ( layer_id , tf . nn . relu ( self . _conv_2d ( W , b )))","title":"relu_conv_2d()"},{"location":"reference/artificial_artwork/style_model/graph_factory/","text":"GraphFactory Source code in src/artificial_artwork/style_model/graph_factory.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 class GraphFactory : builder = GraphBuilder () @classmethod def create ( cls , config : ImageSpecs , model_design ) -> Dict [ str , Any ]: \"\"\"Create a model for the purpose of 'painting'/generating a picture. Creates a Deep Learning Neural Network with most layers having weights (aka model parameters) with values extracted from a pre-trained model (ie another neural network trained on an image dataset suitably). Args: config ([type]): [description] model_parameters ([type], optional): [description]. Defaults to None. Returns: Dict[str, Any]: [description] \"\"\" # each relu_conv_2d uses pretrained model's layer weights for W and b matrices # each average pooling layer uses custom weight values # all weights are guaranteed to remain constant (see GraphBuilder._conv_2d method) # Build the Input Layer of the NST Style Network, based on input Image Specs cls . builder . input ( config ) LayerMaker ( cls . builder , model_design . pretrained_model . reporter , # this reporter is able to extract weights ) . make_layers ( model_design . network_design . network_layers ) # all VGG layers return cls . builder . graph create ( config , model_design ) classmethod Create a model for the purpose of 'painting'/generating a picture. Creates a Deep Learning Neural Network with most layers having weights (aka model parameters) with values extracted from a pre-trained model (ie another neural network trained on an image dataset suitably). Parameters: Name Type Description Default config [ type ] [description] required model_parameters [ type ] [description]. Defaults to None. required Returns: Type Description Dict [ str , Any ] Dict[str, Any]: [description] Source code in src/artificial_artwork/style_model/graph_factory.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @classmethod def create ( cls , config : ImageSpecs , model_design ) -> Dict [ str , Any ]: \"\"\"Create a model for the purpose of 'painting'/generating a picture. Creates a Deep Learning Neural Network with most layers having weights (aka model parameters) with values extracted from a pre-trained model (ie another neural network trained on an image dataset suitably). Args: config ([type]): [description] model_parameters ([type], optional): [description]. Defaults to None. Returns: Dict[str, Any]: [description] \"\"\" # each relu_conv_2d uses pretrained model's layer weights for W and b matrices # each average pooling layer uses custom weight values # all weights are guaranteed to remain constant (see GraphBuilder._conv_2d method) # Build the Input Layer of the NST Style Network, based on input Image Specs cls . builder . input ( config ) LayerMaker ( cls . builder , model_design . pretrained_model . reporter , # this reporter is able to extract weights ) . make_layers ( model_design . network_design . network_layers ) # all VGG layers return cls . builder . graph LayerMaker Automatically create the NST Style Computational Graph (Neural Net) Automatically builds the NST Style Network as a Computational Graph of Tensor Operations, given a list of layer_ids (ie names) and a reporter (ie a ModelReporter instance) that can provide the weights for each layer_id. Automatically creates relu or avg pooling layers, depending on the layer_id. Source code in src/artificial_artwork/style_model/graph_factory.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 @attr . s class LayerMaker : \"\"\"Automatically create the NST Style Computational Graph (Neural Net) Automatically builds the NST Style Network as a Computational Graph of Tensor Operations, given a list of layer_ids (ie names) and a reporter (ie a ModelReporter instance) that can provide the weights for each layer_id. Automatically creates relu or avg pooling layers, depending on the layer_id. \"\"\" graph_builder = attr . ib () reporter = attr . ib () layer_callbacks = attr . ib ( init = False , default = attr . Factory ( lambda self : { \"conv\" : self . _create_relu_layer , \"avgpool\" : self . _create_avg_pool_layer , }, takes_self = True , ), ) regex = attr . ib ( init = False , default = re . compile ( r \"(\\w+?)[\\d_]*$\" )) def make_layers ( self , layers : Iterable [ str ]): for layer_id in layers : self . _build_layer ( layer_id ) def _build_layer ( self , layer_id : str ): match_instance = self . regex . match ( layer_id ) if match_instance is not None : return self . layer_callbacks [ match_instance . group ( 1 )]( layer_id ) raise UnknownLayerError ( f \"Failed to construct layer ' { layer_id } '. Supported layers are \" f \"[ { ', ' . join (( k for k in self . layer_callbacks )) } ] and regex\" f \"used to parse the layer is ' { self . regex . pattern } '\" ) def _create_relu_layer ( self , layer_id : str ): \"\"\"Create Layer Neurons by wrapping a ReLU activation function around a Conv2D Tensor\"\"\" return self . graph_builder . relu_conv_2d ( layer_id , self . reporter . get_weights ( layer_id )) def _create_avg_pool_layer ( self , layer_id : str ): \"\"\"Create Layer as Neurons performing Average Pooling with padding SAME\"\"\" return self . graph_builder . avg_pool ( layer_id )","title":"graph_factory"},{"location":"reference/artificial_artwork/style_model/graph_factory/#artificial_artwork.style_model.graph_factory.GraphFactory","text":"Source code in src/artificial_artwork/style_model/graph_factory.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 class GraphFactory : builder = GraphBuilder () @classmethod def create ( cls , config : ImageSpecs , model_design ) -> Dict [ str , Any ]: \"\"\"Create a model for the purpose of 'painting'/generating a picture. Creates a Deep Learning Neural Network with most layers having weights (aka model parameters) with values extracted from a pre-trained model (ie another neural network trained on an image dataset suitably). Args: config ([type]): [description] model_parameters ([type], optional): [description]. Defaults to None. Returns: Dict[str, Any]: [description] \"\"\" # each relu_conv_2d uses pretrained model's layer weights for W and b matrices # each average pooling layer uses custom weight values # all weights are guaranteed to remain constant (see GraphBuilder._conv_2d method) # Build the Input Layer of the NST Style Network, based on input Image Specs cls . builder . input ( config ) LayerMaker ( cls . builder , model_design . pretrained_model . reporter , # this reporter is able to extract weights ) . make_layers ( model_design . network_design . network_layers ) # all VGG layers return cls . builder . graph","title":"GraphFactory"},{"location":"reference/artificial_artwork/style_model/graph_factory/#artificial_artwork.style_model.graph_factory.GraphFactory.create","text":"Create a model for the purpose of 'painting'/generating a picture. Creates a Deep Learning Neural Network with most layers having weights (aka model parameters) with values extracted from a pre-trained model (ie another neural network trained on an image dataset suitably). Parameters: Name Type Description Default config [ type ] [description] required model_parameters [ type ] [description]. Defaults to None. required Returns: Type Description Dict [ str , Any ] Dict[str, Any]: [description] Source code in src/artificial_artwork/style_model/graph_factory.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @classmethod def create ( cls , config : ImageSpecs , model_design ) -> Dict [ str , Any ]: \"\"\"Create a model for the purpose of 'painting'/generating a picture. Creates a Deep Learning Neural Network with most layers having weights (aka model parameters) with values extracted from a pre-trained model (ie another neural network trained on an image dataset suitably). Args: config ([type]): [description] model_parameters ([type], optional): [description]. Defaults to None. Returns: Dict[str, Any]: [description] \"\"\" # each relu_conv_2d uses pretrained model's layer weights for W and b matrices # each average pooling layer uses custom weight values # all weights are guaranteed to remain constant (see GraphBuilder._conv_2d method) # Build the Input Layer of the NST Style Network, based on input Image Specs cls . builder . input ( config ) LayerMaker ( cls . builder , model_design . pretrained_model . reporter , # this reporter is able to extract weights ) . make_layers ( model_design . network_design . network_layers ) # all VGG layers return cls . builder . graph","title":"create()"},{"location":"reference/artificial_artwork/style_model/graph_factory/#artificial_artwork.style_model.graph_factory.LayerMaker","text":"Automatically create the NST Style Computational Graph (Neural Net) Automatically builds the NST Style Network as a Computational Graph of Tensor Operations, given a list of layer_ids (ie names) and a reporter (ie a ModelReporter instance) that can provide the weights for each layer_id. Automatically creates relu or avg pooling layers, depending on the layer_id. Source code in src/artificial_artwork/style_model/graph_factory.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 @attr . s class LayerMaker : \"\"\"Automatically create the NST Style Computational Graph (Neural Net) Automatically builds the NST Style Network as a Computational Graph of Tensor Operations, given a list of layer_ids (ie names) and a reporter (ie a ModelReporter instance) that can provide the weights for each layer_id. Automatically creates relu or avg pooling layers, depending on the layer_id. \"\"\" graph_builder = attr . ib () reporter = attr . ib () layer_callbacks = attr . ib ( init = False , default = attr . Factory ( lambda self : { \"conv\" : self . _create_relu_layer , \"avgpool\" : self . _create_avg_pool_layer , }, takes_self = True , ), ) regex = attr . ib ( init = False , default = re . compile ( r \"(\\w+?)[\\d_]*$\" )) def make_layers ( self , layers : Iterable [ str ]): for layer_id in layers : self . _build_layer ( layer_id ) def _build_layer ( self , layer_id : str ): match_instance = self . regex . match ( layer_id ) if match_instance is not None : return self . layer_callbacks [ match_instance . group ( 1 )]( layer_id ) raise UnknownLayerError ( f \"Failed to construct layer ' { layer_id } '. Supported layers are \" f \"[ { ', ' . join (( k for k in self . layer_callbacks )) } ] and regex\" f \"used to parse the layer is ' { self . regex . pattern } '\" ) def _create_relu_layer ( self , layer_id : str ): \"\"\"Create Layer Neurons by wrapping a ReLU activation function around a Conv2D Tensor\"\"\" return self . graph_builder . relu_conv_2d ( layer_id , self . reporter . get_weights ( layer_id )) def _create_avg_pool_layer ( self , layer_id : str ): \"\"\"Create Layer as Neurons performing Average Pooling with padding SAME\"\"\" return self . graph_builder . avg_pool ( layer_id )","title":"LayerMaker"},{"location":"reference/artificial_artwork/termination_condition/","text":"","title":"termination_condition"},{"location":"reference/artificial_artwork/termination_condition/termination_condition/","text":"","title":"termination_condition"},{"location":"reference/artificial_artwork/termination_condition/termination_condition_interface/","text":"TerminationConditionInterface Bases: ABC , Generic [ T ] A condition that evaluates to True or False. If True it should indicate that something should now terminate. Source code in src/artificial_artwork/termination_condition/termination_condition_interface.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class TerminationConditionInterface ( ABC , Generic [ T ]): \"\"\"A condition that evaluates to True or False. If True it should indicate that something should now terminate. \"\"\" @abstractmethod def satisfied ( self , progress : T ) -> bool : \"\"\"Check if the termination condition is True. Args: progress ([type]): [description] Returns: bool: True if the termination condition is satisfied, else False \"\"\" raise NotImplementedError satisfied ( progress ) abstractmethod Check if the termination condition is True. Parameters: Name Type Description Default progress [ type ] [description] required Returns: Name Type Description bool bool True if the termination condition is satisfied, else False Source code in src/artificial_artwork/termination_condition/termination_condition_interface.py 13 14 15 16 17 18 19 20 21 22 23 @abstractmethod def satisfied ( self , progress : T ) -> bool : \"\"\"Check if the termination condition is True. Args: progress ([type]): [description] Returns: bool: True if the termination condition is satisfied, else False \"\"\" raise NotImplementedError","title":"termination_condition_interface"},{"location":"reference/artificial_artwork/termination_condition/termination_condition_interface/#artificial_artwork.termination_condition.termination_condition_interface.TerminationConditionInterface","text":"Bases: ABC , Generic [ T ] A condition that evaluates to True or False. If True it should indicate that something should now terminate. Source code in src/artificial_artwork/termination_condition/termination_condition_interface.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class TerminationConditionInterface ( ABC , Generic [ T ]): \"\"\"A condition that evaluates to True or False. If True it should indicate that something should now terminate. \"\"\" @abstractmethod def satisfied ( self , progress : T ) -> bool : \"\"\"Check if the termination condition is True. Args: progress ([type]): [description] Returns: bool: True if the termination condition is satisfied, else False \"\"\" raise NotImplementedError","title":"TerminationConditionInterface"},{"location":"reference/artificial_artwork/termination_condition/termination_condition_interface/#artificial_artwork.termination_condition.termination_condition_interface.TerminationConditionInterface.satisfied","text":"Check if the termination condition is True. Parameters: Name Type Description Default progress [ type ] [description] required Returns: Name Type Description bool bool True if the termination condition is satisfied, else False Source code in src/artificial_artwork/termination_condition/termination_condition_interface.py 13 14 15 16 17 18 19 20 21 22 23 @abstractmethod def satisfied ( self , progress : T ) -> bool : \"\"\"Check if the termination condition is True. Args: progress ([type]): [description] Returns: bool: True if the termination condition is satisfied, else False \"\"\" raise NotImplementedError","title":"satisfied()"}]}